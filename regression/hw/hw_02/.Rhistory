#search for best alpha
for(a in 1:length(alphas)){
alpha = alphas[a]
e_cv = cv.glmnet(e_train[,-6], e_train[,6],
alpha = alpha,
nfolds = 5,
nlambda = 20,
type.measure = 'mse',
family='gaussian',
standardize = TRUE)
lambda = e_cv$lambda.min
y_hat = round(predict(e_cv, s = lambda, newx = e_test[,-6]),0)
y = e_test[,6]
mse = sum((y_hat-y)**2)/nrow(e_test)
if(mse<best_mse){
best_mse = mse
el_net_mse = best_mse
best_alpha = alpha
best_lambda = lambda
best_model = e_cv
}
e_net = best_model
}
e_net = cv.glmnet(data.matrix(cc[,-6]), data.matrix(cc[,6]),
alpha = best_alpha,
nfolds = 5,
nlambda = 20,
type.measure = 'mse',
family='gaussian',
standardize = TRUE)
e_l = coef(e_net, s = best_lambda)
e_coeffs = e_l@Dimnames[[1]][e_l@i + 1] %>%
.[2:length(.)]
e_net_mse = formatC(mean(e_net$cvm), format = "e", digits = 2)
formula_1 = formula(Bare_Nuclei~ .)
e_data = data.frame(cc)[e_coeffs]
e_data$Bare_Nuclei = cc$Bare_Nuclei
e_cv = cv.lm(data = e_data, form.lm=formula_1, m=10, printit = FALSE)
e_mse = attr(e_cv,'ms')
e_mse = formatC(e_mse, format = "e", digits = 2)
model_lm = lm(Bare_Nuclei~ ., train)
y_hat = predict(model_lm, test)
y = test$Bare_Nuclei
error_lm = y_hat-y
library(randomForest)
num_pred = 5
model_rf = randomForest(Bare_Nuclei~.,
data = train,
mtry = num_pred,
importance = TRUE,
ntree = 1000)
y = as.numeric(test$Bare_Nuclei)
y_hat = as.numeric(predict(model_rf, test))
error_rf = (y_hat - y)
mse_rf = round(mean(error_rf**2),2)
mse_rf = formatC(mse_rf, format = "e", digits = 2)
hist(error_rf)
regression_data = copy(data)
prediction_rf =predict(model_rf, data[is.na(data$Bare_Nuclei),-7])
regression_data[missing,7]=round(prediction_rf,0)
perturb_data = copy(data)
perturbed_rf = round(prediction_rf+sample(error_rf,16), 0)
perturb_data[missing,7] = perturbed_rf
prediction_lm = predict(model_lm, data[is.na(data$Bare_Nuclei),-7])
perturbed_lm = round(prediction_lm+sample(error_lm,16), 0)
compare = data.table(RF = round(prediction_rf,0), LM = round(prediction_lm,0), RF_Perturbed = perturbed_rf, LM_Perturbed = perturbed_lm)
compare
#show mse for both regression show histogram of error explain what you did, compare the models with the data.
library(caret)
library(e1071)
split_data = function(data, train_frac=.8){
## 75% of the sample size
data = data.frame(data)
data$Class = as.factor(data$Class)
#data = sapply( data, as.factor )
smp_size = floor(train_frac * nrow(data))
train_ind = sample(seq_len(nrow(data)), size = smp_size)
train = data[train_ind,]
test = data[-train_ind,]
return(list(train, test))
}
caret_model = function(x,y, method = "svmLinear", trctrl, tuneGrid){
set.seed(343)
model <- train(x = x, y = y, method = method,
trControl=trctrl,
tuneGrid = tuneGrid,
tuneLength = 10)
return(model)
}
svm_grid <- expand.grid(C = c(.0000000000001, .0000001, 0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1, 10, 100, 500, 1000, 10000))
knn_grid <- expand.grid(k = c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15))
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
methods = list("svmLinear", 'knn')
grids = list(svm_grid, knn_grid)
data_sets = list(mean_data, mode_data, regression_data, perturb_data)
svm = NULL
svm_matrix = NULL
knn = NULL
knn_matrix = NULL
for(m in 1:length(methods)){
method = methods[[m]]
grid = grids[[m]]
for(d in 1:length(data_sets)){
data_set = data_sets[[d]]
data_name = data_names[[d]]
tt = split_data(data_set, train_frac=.8)
trn = tt[[1]][,-1]
x_trn = sapply(trn[,1:9], as.numeric)
y_trn = trn[,10]
test = tt[[2]][,-1]
x_tst = data.frame(sapply(test[,1:9], as.numeric))
y_tst = test[,10]
test_pred = predict(model, newdata =x_tst)
conf_mat = confusionMatrix(test_pred, y_tst )
model = caret_model(x = x_trn, y = y_trn, method=method, trctrl=trctrl, tuneGrid = grid)
if(method == 'svmLinear'){
svm[[d]] = model
svm_matrix[[d]] = conf_mat
}else{
knn[[d]] = model
knn_matrix[[d]] = conf_mat
}
}
}
library(caret)
library(e1071)
split_data = function(data, train_frac=.8){
## 75% of the sample size
data = data.frame(data)
data$Class = as.factor(data$Class)
#data = sapply( data, as.factor )
smp_size = floor(train_frac * nrow(data))
train_ind = sample(seq_len(nrow(data)), size = smp_size)
train = data[train_ind,]
test = data[-train_ind,]
return(list(train, test))
}
caret_model = function(x,y, method = "svmLinear", trctrl, tuneGrid){
set.seed(343)
model <- train(x = x, y = y, method = method,
trControl=trctrl,
tuneGrid = tuneGrid,
tuneLength = 10)
return(model)
}
svm_grid <- expand.grid(C = c(.0000000000001, .0000001, 0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1, 10, 100, 500, 1000, 10000))
knn_grid <- expand.grid(k = c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15))
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
methods = list("svmLinear", 'knn')
grids = list(svm_grid, knn_grid)
data_sets = list(mean_data, mode_data, regression_data, perturb_data)
svm = NULL
svm_matrix = NULL
knn = NULL
knn_matrix = NULL
for(m in 1:length(methods)){
method = methods[[m]]
grid = grids[[m]]
for(d in 1:length(data_sets)){
data_set = data_sets[[d]]
tt = split_data(data_set, train_frac=.8)
trn = tt[[1]][,-1]
x_trn = sapply(trn[,1:9], as.numeric)
y_trn = trn[,10]
test = tt[[2]][,-1]
x_tst = data.frame(sapply(test[,1:9], as.numeric))
y_tst = test[,10]
test_pred = predict(model, newdata =x_tst)
conf_mat = confusionMatrix(test_pred, y_tst )
model = caret_model(x = x_trn, y = y_trn, method=method, trctrl=trctrl, tuneGrid = grid)
if(method == 'svmLinear'){
svm[[d]] = model
svm_matrix[[d]] = conf_mat
}else{
knn[[d]] = model
knn_matrix[[d]] = conf_mat
}
}
}
library(caret)
library(e1071)
split_data = function(data, train_frac=.8){
## 75% of the sample size
data = data.frame(data)
data$Class = as.factor(data$Class)
#data = sapply( data, as.factor )
smp_size = floor(train_frac * nrow(data))
train_ind = sample(seq_len(nrow(data)), size = smp_size)
train = data[train_ind,]
test = data[-train_ind,]
return(list(train, test))
}
caret_model = function(x,y, method = "svmLinear", trctrl, tuneGrid){
set.seed(343)
model <- train(x = x, y = y, method = method,
trControl=trctrl,
tuneGrid = tuneGrid,
tuneLength = 10)
return(model)
}
svm_grid <- expand.grid(C = c(.0000000000001, .0000001, 0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1, 10, 100, 500, 1000, 10000))
knn_grid <- expand.grid(k = c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15))
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
methods = list("svmLinear", 'knn')
grids = list(svm_grid, knn_grid)
data_sets = list(mean_data, mode_data, regression_data, perturb_data)
svm = NULL
svm_matrix = NULL
knn = NULL
knn_matrix = NULL
for(m in 1:length(methods)){
method = methods[[m]]
grid = grids[[m]]
for(d in 1:length(data_sets)){
data_set = data_sets[[d]]
tt = split_data(data_set, train_frac=.8)
trn = tt[[1]][,-1]
x_trn = sapply(trn[,1:9], as.numeric)
y_trn = trn[,10]
test = tt[[2]][,-1]
x_tst = data.frame(sapply(test[,1:9], as.numeric))
y_tst = test[,10]
model = caret_model(x = x_trn, y = y_trn, method=method, trctrl=trctrl, tuneGrid = grid)
test_pred = predict(model, newdata =x_tst)
conf_mat = confusionMatrix(test_pred, y_tst )
if(method == 'svmLinear'){
svm[[d]] = model
svm_matrix[[d]] = conf_mat
}else{
knn[[d]] = model
knn_matrix[[d]] = conf_mat
}
}
}
svm_matrix[[1]]
svm_matrix[[2]]
svm_matrix[[3]]
svm_matrix[[4]]
svm_matrix[[5]]
knn_matrix[[1]]
knn_matrix[[2]]
knn_matrix[[3]]
knn_matrix[[]]
knn_matrix[[4]]
knn_matrix[[2]]
library(caret)
library(e1071)
split_data = function(data, train_frac=.8){
## 75% of the sample size
data = data.frame(data)
data$Class = as.factor(data$Class)
#data = sapply( data, as.factor )
smp_size = floor(train_frac * nrow(data))
train_ind = sample(seq_len(nrow(data)), size = smp_size)
train = data[train_ind,]
test = data[-train_ind,]
return(list(train, test))
}
caret_model = function(x,y, method = "svmLinear", trctrl, tuneGrid){
set.seed(343)
model <- train(x = x, y = y, method = method,
trControl=trctrl,
tuneGrid = tuneGrid,
tuneLength = 10)
return(model)
}
svm_grid <- expand.grid(C = c(.0000000000001, .0000001, 0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1, 10, 100, 500, 1000, 10000))
knn_grid <- expand.grid(k = c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15))
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
methods = list("svmLinear", 'knn')
grids = list(svm_grid, knn_grid)
data_sets = list(mean_data, mode_data, regression_data, perturb_data,cc)
svm = NULL
svm_matrix = NULL
knn = NULL
knn_matrix = NULL
for(m in 1:length(methods)){
method = methods[[m]]
grid = grids[[m]]
for(d in 1:length(data_sets)){
data_set = data_sets[[d]]
tt = split_data(data_set, train_frac=.8)
trn = tt[[1]][,-1]
x_trn = sapply(trn[,1:9], as.numeric)
y_trn = trn[,10]
test = tt[[2]][,-1]
x_tst = data.frame(sapply(test[,1:9], as.numeric))
y_tst = test[,10]
model = caret_model(x = x_trn, y = y_trn, method=method, trctrl=trctrl, tuneGrid = grid)
test_pred = predict(model, newdata =x_tst)
conf_mat = confusionMatrix(test_pred, y_tst )
if(method == 'svmLinear'){
svm[[d]] = model
svm_matrix[[d]] = conf_mat
}else{
knn[[d]] = model
knn_matrix[[d]] = conf_mat
}
}
}
library(caret)
library(e1071)
split_data = function(data, train_frac=.8){
## 75% of the sample size
data = data.frame(data)
data$Class = as.factor(data$Class)
#data = sapply( data, as.factor )
smp_size = floor(train_frac * nrow(data))
train_ind = sample(seq_len(nrow(data)), size = smp_size)
train = data[train_ind,]
test = data[-train_ind,]
return(list(train, test))
}
caret_model = function(x,y, method = "svmLinear", trctrl, tuneGrid){
set.seed(343)
model <- train(x = x, y = y, method = method,
trControl=trctrl,
tuneGrid = tuneGrid,
tuneLength = 10)
return(model)
}
svm_grid <- expand.grid(C = c(.0000000000001, .0000001, 0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1, 10, 100, 500, 1000, 10000))
knn_grid <- expand.grid(k = c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15))
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
methods = list("svmLinear", 'knn')
grids = list(svm_grid, knn_grid)
data_sets = list(mean_data, mode_data, regression_data, perturb_data,cc)
svm = NULL
svm_matrix = NULL
knn = NULL
knn_matrix = NULL
for(m in 1:length(methods)){
method = methods[[m]]
grid = grids[[m]]
for(d in 1:length(data_sets)){
data_set = data_sets[[d]]
tt = split_data(data_set, train_frac=.8)
trn = tt[[1]][,-1]
x_trn = sapply(trn[,1:9], as.numeric)
y_trn = trn[,10]
test = tt[[2]][,-1]
x_tst = data.frame(sapply(test[,1:9], as.numeric))
y_tst = test[,10]
model = caret_model(x = x_trn, y = y_trn, method=method, trctrl=trctrl, tuneGrid = grid)
test_pred = predict(model, newdata =x_tst)
conf_mat = confusionMatrix(test_pred, y_tst )
if(method == 'svmLinear'){
svm[[d]] = model
svm_matrix[[d]] = conf_mat
}else{
knn[[d]] = model
knn_matrix[[d]] = conf_mat
}
}
}
svm[[1]]
svm[[1]]$preProcess
svm[[1]][1]
svm[[1]][2]
svm[[1]][3]
svm[[1]][4]
svm[[1]]$results$Accuracy
max(svm[[1]]$results$Accuracy)
svm_matrix[[1]]
svm_matrix[[1]]$table
svm_matrix[[1]]$overall
svm_matrix[[1]]$overall$Accuracy
svm_matrix[[1]]$overall[1]
svm_matrix[[1]]$overall[1][1]
svm_matrix[[1]]$overall[[1]]
#svm = NULL
#svm_matrix = NULL
#knn = NULL
#knn_matrix = NULL
for( i in 1:length(svm_matrix)){
best_svm = -1/0
svm_index = 0
best_knn = -1/0
knn_index = 0
if (svm_matrix[[i]]$overall[[1]]>best_svm){
best_svm =svm_matrix[[i]]$overall[[1]]
svm_index = i
}
if (knn_matrix[[i]]$overall[[1]]>best_knn){
best_knn =knn_matrix[[i]]$overall[[1]]
knn_index = i
}
}
best_knn
best_svm
#svm = NULL
#svm_matrix = NULL
#knn = NULL
#knn_matrix = NULL
for( i in 1:length(svm_matrix)){
best_svm = -1/0
best_knn = -1/0
if (svm_matrix[[i]]$overall[[1]]>best_svm){
best_svm =svm_matrix[[i]]$overall[[1]]
best_svm_mat = svm_matrix[i]
}
if (knn_matrix[[i]]$overall[[1]]>best_knn){
best_knn =knn_matrix[[i]]$overall[[1]]
best_knn_mat = knn_matrix[i]
}
}
best_knn_mat
best_svm_mat
mean_knn_acc = knn_matrix[[1]]$overall[[1]]
mode_knn_acc = knn_matrix[[2]]$overall[[1]]
reg_knn_acc = knn_matrix[[3]]$overall[[1]]
per_knn_acc = knn_matrix[[4]]$overall[[1]]
cc_knn_acc = knn_matrix[[5]]$overall[[1]]
mean_svm_acc = svm_matrix[[1]]$overall[[1]]
mode_svm_acc = svm_matrix[[2]]$overall[[1]]
reg_svm_acc = svm_matrix[[3]]$overall[[1]]
per_svm_acc = svm_matrix[[4]]$overall[[1]]
cc_svm_acc = svm_matrix[[5]]$overall[[1]]
mean_svm_acc
mode_svm_acc
reg_svm_acc
per_svm_acc
cc_svm_acc
mean_knn_acc
mode_knn_acc
reg_knn_acc
per_knn_acc
cc_knn_acc
knn[[1]]
knn[[1]]$results
knn[[1]]$results$Accuracy
max(knn[[1]]$results$Accuracy)
mean_knn_acc = round(knn_matrix[[1]]$overall[[1]],2)
mode_knn_acc = round(knn_matrix[[2]]$overall[[1]],2)
reg_knn_acc = round(knn_matrix[[3]]$overall[[1]],2)
per_knn_acc = round(knn_matrix[[4]]$overall[[1]],2)
cc_knn_acc = round(knn_matrix[[5]]$overall[[1]],2)
install.packages('devtools') #assuming it is not already installed
library(devtools)
install_github('andreacirilloac/updateR')
library(updateR)
updateR(admin_password = 'Admin user password')
library("knitr", lib.loc="/Library/Frameworks/R.framework/Versions/3.5/Resources/library")
install.packages(c("caret", "cli", "data.table", "digest", "dimRed", "dplyr", "evaluate", "fansi", "foreign", "ggplot2", "greybox", "haven", "ipred", "lattice", "lava", "MASS", "Matrix", "mgcv", "mime", "ModelMetrics", "nloptr", "openssl", "ps", "R6", "Rcpp", "RcppArmadillo", "readr", "recipes", "reshape", "rlang", "rpart.plot", "rstudioapi", "sfsmisc", "survival", "tidyr", "tidyselect", "tinytex", "tseries", "TTR", "xfun", "xts", "zoo"))
install.packages(c("caret", "cli", "data.table", "digest", "dimRed", "dplyr", "evaluate", "fansi", "foreign", "ggplot2", "greybox", "haven", "ipred", "lattice", "lava", "MASS", "Matrix", "mgcv", "mime", "ModelMetrics", "nloptr", "openssl", "ps", "R6", "Rcpp", "RcppArmadillo", "readr", "recipes", "reshape", "rlang", "rpart.plot", "rstudioapi", "sfsmisc", "survival", "tidyr", "tidyselect", "tinytex", "tseries", "TTR", "xfun", "xts", "zoo"))
install.packages(c("caret", "cli", "data.table", "digest", "dimRed", "dplyr", "evaluate", "fansi", "foreign", "ggplot2", "greybox", "haven", "ipred", "lattice", "lava", "MASS", "Matrix", "mgcv", "mime", "ModelMetrics", "nloptr", "openssl", "ps", "R6", "Rcpp", "RcppArmadillo", "readr", "recipes", "reshape", "rlang", "rpart.plot", "rstudioapi", "sfsmisc", "survival", "tidyr", "tidyselect", "tinytex", "tseries", "TTR", "xfun", "xts", "zoo"))
install.packages(c("caret", "cli", "data.table", "digest", "dimRed", "dplyr", "evaluate", "fansi", "foreign", "ggplot2", "greybox", "haven", "ipred", "lattice", "lava", "MASS", "Matrix", "mgcv", "mime", "ModelMetrics", "nloptr", "openssl", "ps", "R6", "Rcpp", "RcppArmadillo", "readr", "recipes", "reshape", "rlang", "rpart.plot", "rstudioapi", "sfsmisc", "survival", "tidyr", "tidyselect", "tinytex", "tseries", "TTR", "xfun", "xts", "zoo"))
install.packages(c("caret", "cli", "data.table", "digest", "dimRed", "dplyr", "evaluate", "fansi", "foreign", "ggplot2", "greybox", "haven", "ipred", "lattice", "lava", "MASS", "Matrix", "mgcv", "mime", "ModelMetrics", "nloptr", "openssl", "ps", "R6", "Rcpp", "RcppArmadillo", "readr", "recipes", "reshape", "rlang", "rpart.plot", "rstudioapi", "sfsmisc", "survival", "tidyr", "tidyselect", "tinytex", "tseries", "TTR", "xfun", "xts", "zoo"))
detach("package:stats", unload=TRUE)
detach("package:usethis", unload=TRUE)
detach("package:utils", unload=TRUE)
detach("package:xml2", unload=TRUE)
detach("package:graphics", unload=TRUE)
detach("package:grDevices", unload=TRUE)
detach("package:assertthat", unload=TRUE)
install.packages(c("caret", "cli", "data.table", "digest", "dimRed", "dplyr", "evaluate", "fansi", "foreign", "ggplot2", "greybox", "haven", "ipred", "lattice", "lava", "MASS", "Matrix", "mgcv", "mime", "ModelMetrics", "nloptr", "openssl", "ps", "R6", "Rcpp", "RcppArmadillo", "readr", "recipes", "reshape", "rlang", "rpart.plot", "rstudioapi", "sfsmisc", "survival", "tidyr", "tidyselect", "tinytex", "tseries", "TTR", "xfun", "xts", "zoo"))
detach("package:dplyr", unload=TRUE)
detach("package:magrittr", unload=TRUE)
detach("package:methods", unload=TRUE)
install.packages(c("caret", "cli", "data.table", "digest", "dimRed", "dplyr", "evaluate", "fansi", "foreign", "ggplot2", "greybox", "haven", "ipred", "lattice", "lava", "MASS", "Matrix", "mgcv", "mime", "ModelMetrics", "nloptr", "openssl", "ps", "R6", "Rcpp", "RcppArmadillo", "readr", "recipes", "reshape", "rlang", "rpart.plot", "rstudioapi", "sfsmisc", "survival", "tidyr", "tidyselect", "tinytex", "tseries", "TTR", "xfun", "xts", "zoo"))
install.packages(c("caret", "cli", "data.table", "digest", "dimRed", "dplyr", "evaluate", "fansi", "foreign", "ggplot2", "greybox", "haven", "ipred", "lattice", "lava", "MASS", "Matrix", "mgcv", "mime", "ModelMetrics", "nloptr", "openssl", "ps", "R6", "Rcpp", "RcppArmadillo", "readr", "recipes", "reshape", "rlang", "rpart.plot", "rstudioapi", "sfsmisc", "survival", "tidyr", "tidyselect", "tinytex", "tseries", "TTR", "xfun", "xts", "zoo"))
install.packages(c("caret", "cli", "data.table", "digest", "dimRed", "dplyr", "evaluate", "fansi", "foreign", "ggplot2", "greybox", "haven", "ipred", "lattice", "lava", "MASS", "Matrix", "mgcv", "mime", "ModelMetrics", "nloptr", "openssl", "ps", "R6", "Rcpp", "RcppArmadillo", "readr", "recipes", "reshape", "rlang", "rpart.plot", "rstudioapi", "sfsmisc", "survival", "tidyr", "tidyselect", "tinytex", "tseries", "TTR", "xfun", "xts", "zoo"))
knitr::opts_chunk$set(echo = TRUE, fig.pos= "H")
confint(model_log, level = .95)
data = read.csv("Highway1.csv", head = TRUE, sep = ",")
rate = as.numeric(data[,2])
signs = as.numeric(data[,6])
cor_coef = round(cor(signs, rate),3)
cor_coef_log = round(cor(log(signs), log(rate)),3)
plot(signs, rate)
plot(log(signs), log(rate))
model = lm(rate ~ signs)
model_log = lm(log(rate) ~ log(signs))
coefs = model$coefficients
slope = round(coefs[2],3)
intercept = round(coefs[1], 3)
summary(model)
1-pt(4.6,37)
confint(model, level = .95)
confint(model_log, level = .95)
confint(model, level = .95)
exp(confint(model_log, level = .95))
predict.lm(model, new, interval="predict", level = .95)
new = data.frame(signs = 1.25)
predict.lm(model, new, interval="predict", level = .95)
exp(predict.lm(model_log, new, interval="predict", level = .95))
model = lm(rate ~ signs)
model_log = lm(log(rate) ~ log(signs))
coefs = model$coefficients
slope = round(coefs[2],3)
intercept = round(coefs[1], 3)
summary(model)
summary(model_log)
data = read.csv("fram.csv", header=TRUE)
data$SEX <- as.factor(data$SEX)
data$CURSMOKE <- as.factor(data$CURSMOKE)
getwd()
cwd("/Users/jfftilton/gitClones/omsa/regression/hw_02")
setwd("/Users/jfftilton/gitClones/omsa/regression/hw_02")
setwd("/Users/jfftilton/gitClones/omsa")
setwd("/Users/jfftilton/gitClones/omsa/regression/hw/hw_02")
data = read.csv("fram.csv", header=TRUE)
data$SEX <- as.factor(data$SEX)
data$CURSMOKE <- as.factor(data$CURSMOKE)
head(data)
model = lm(SYSBP ~., data
model = lm(SYSBP ~., data)
model = lm(SYSBP ~., data)
summary(model)
data3 <- data[data$BMI>=30,]
model2 = lm(SYSBP ~., data3)
summary(model2)
