\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}K-means}{1}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Steps for K-means}{1}{subsection.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Euclidean Distance}{1}{subsection.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces New cluster centers after one iteration of K-means using Euclidean distance\relax }}{2}{figure.caption.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Manhattan Distance}{2}{subsection.1.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces New cluster centers after one iteration of K-means using Manhattan distance\relax }}{2}{figure.caption.2}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Spectral Clustering}{2}{section.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{spectral}{{3a}{3}{Cluster results from spectral clustering.\relax }{figure.caption.3}{}}
\newlabel{sub@spectral}{{a}{3}{Cluster results from spectral clustering.\relax }{figure.caption.3}{}}
\newlabel{kmeans}{{3b}{3}{Cluster results using K-means clustering.\relax }{figure.caption.3}{}}
\newlabel{sub@kmeans}{{b}{3}{Cluster results using K-means clustering.\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Two different clustering algorithm results on the same dataset. The spectral clustering used k nearest neighbors with 2 neighbors to build an adjacency matrix, then k-means on the results from eigendecomposition on the Laplacian matrix. K-means used Euclidean distance as measure. \relax }}{3}{figure.caption.3}}
\newlabel{clusterCompare}{{3}{3}{Two different clustering algorithm results on the same dataset. The spectral clustering used k nearest neighbors with 2 neighbors to build an adjacency matrix, then k-means on the results from eigendecomposition on the Laplacian matrix. K-means used Euclidean distance as measure. \relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Principal Component Analysis}{3}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Find the first principal direction.}{3}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}When we reduce the dimensionality from 3 to 1 based on the principal direction you found above, what is the reconstruction error in terms of variance?}{4}{subsection.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}You are given the following 2-D datasets, approximately draw the first and second principal directional on each plot.}{4}{subsection.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The first 2 principal directions of 2 data clouds.\relax }}{4}{figure.caption.4}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Eigenfaces}{5}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Produce eigenfaces for given dataset}{5}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Plot the top 6 eigenfaces for each subject}{5}{subsubsection.4.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Eigenfaces produced with the first 6 eigenvectors of 2 different face subjects.\relax }}{5}{figure.caption.5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}What is the interpretation of the top 6 eigenfaces?}{5}{subsubsection.4.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Face Recognition}{5}{subsection.4.2}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Mean correlation coefficients between test photo and eigenfaces 1-6\relax }}{6}{table.caption.6}}
\@writefile{toc}{\contentsline {section}{\numberline {5}ISOMAP}{6}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Visualize the similarity graph (e.g., plot the adjacency matrix where weights are shown using intensity).}{6}{subsection.5.1}}
\newlabel{A}{{6a}{6}{A\relax }{figure.caption.7}{}}
\newlabel{sub@A}{{a}{6}{A\relax }{figure.caption.7}{}}
\newlabel{W}{{6b}{6}{W\relax }{figure.caption.7}{}}
\newlabel{sub@W}{{b}{6}{W\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Two similarity Graphs. A: Similarity graph with vertices corresponding to a 1 for the first $k=100$ nearest neighbors, 0 otherwise. W: Similarity graph with vertices corresponding to the euclidean distance for the first $k=100$ nearest neighbors, arbitrarily large value otherwise.\relax }}{6}{figure.caption.7}}
\newlabel{clusterCompare}{{6}{6}{Two similarity Graphs. A: Similarity graph with vertices corresponding to a 1 for the first $k=100$ nearest neighbors, 0 otherwise. W: Similarity graph with vertices corresponding to the euclidean distance for the first $k=100$ nearest neighbors, arbitrarily large value otherwise.\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Implement the ISOMAP algorithm and apply it to this graph to obtain a d = 2-dimensional embedding. Present a plot of this embedding. Find three points that are close to each other and show what they look like. Do you see any similarity among them?}{6}{subsection.5.2}}
\newlabel{embedding}{{7a}{8}{ISOMAP embedding\relax }{figure.caption.8}{}}
\newlabel{sub@embedding}{{a}{8}{ISOMAP embedding\relax }{figure.caption.8}{}}
\newlabel{iso_faces}{{7b}{8}{Close proximity faces\relax }{figure.caption.8}{}}
\newlabel{sub@iso_faces}{{b}{8}{Close proximity faces\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Plot a shows the 2-dimensional embedding of the faces after the ISOMAP algorithm is applied. Figure b is a selection of 3 groups of 5 faces that are in close proximity after ISOMAP dimensionality reduction.\relax }}{8}{figure.caption.8}}
\newlabel{clusterCompare}{{7}{8}{Plot a shows the 2-dimensional embedding of the faces after the ISOMAP algorithm is applied. Figure b is a selection of 3 groups of 5 faces that are in close proximity after ISOMAP dimensionality reduction.\relax }{figure.caption.8}{}}
