{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "df = pd.read_csv(\"spambase.data\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.104553</td>\n",
       "      <td>0.213015</td>\n",
       "      <td>0.280656</td>\n",
       "      <td>0.065425</td>\n",
       "      <td>0.312223</td>\n",
       "      <td>0.095901</td>\n",
       "      <td>0.114208</td>\n",
       "      <td>0.105295</td>\n",
       "      <td>0.090067</td>\n",
       "      <td>0.239413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038575</td>\n",
       "      <td>0.139030</td>\n",
       "      <td>0.016976</td>\n",
       "      <td>0.269071</td>\n",
       "      <td>0.075811</td>\n",
       "      <td>0.044238</td>\n",
       "      <td>5.191515</td>\n",
       "      <td>52.172789</td>\n",
       "      <td>283.289285</td>\n",
       "      <td>0.394045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.305358</td>\n",
       "      <td>1.290575</td>\n",
       "      <td>0.504143</td>\n",
       "      <td>1.395151</td>\n",
       "      <td>0.672513</td>\n",
       "      <td>0.273824</td>\n",
       "      <td>0.391441</td>\n",
       "      <td>0.401071</td>\n",
       "      <td>0.278616</td>\n",
       "      <td>0.644755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243471</td>\n",
       "      <td>0.270355</td>\n",
       "      <td>0.109394</td>\n",
       "      <td>0.815672</td>\n",
       "      <td>0.245882</td>\n",
       "      <td>0.429342</td>\n",
       "      <td>31.729449</td>\n",
       "      <td>194.891310</td>\n",
       "      <td>606.347851</td>\n",
       "      <td>0.488698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.588000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.276000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.706000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.540000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>42.810000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.385000</td>\n",
       "      <td>9.752000</td>\n",
       "      <td>4.081000</td>\n",
       "      <td>32.478000</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.829000</td>\n",
       "      <td>1102.500000</td>\n",
       "      <td>9989.000000</td>\n",
       "      <td>15841.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  4601.000000  4601.000000  4601.000000  4601.000000  4601.000000   \n",
       "mean      0.104553     0.213015     0.280656     0.065425     0.312223   \n",
       "std       0.305358     1.290575     0.504143     1.395151     0.672513   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.420000     0.000000     0.380000   \n",
       "max       4.540000    14.280000     5.100000    42.810000    10.000000   \n",
       "\n",
       "                5            6            7            8            9   ...  \\\n",
       "count  4601.000000  4601.000000  4601.000000  4601.000000  4601.000000  ...   \n",
       "mean      0.095901     0.114208     0.105295     0.090067     0.239413  ...   \n",
       "std       0.273824     0.391441     0.401071     0.278616     0.644755  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.160000  ...   \n",
       "max       5.880000     7.270000    11.110000     5.260000    18.180000  ...   \n",
       "\n",
       "                48           49           50           51           52  \\\n",
       "count  4601.000000  4601.000000  4601.000000  4601.000000  4601.000000   \n",
       "mean      0.038575     0.139030     0.016976     0.269071     0.075811   \n",
       "std       0.243471     0.270355     0.109394     0.815672     0.245882   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.065000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.188000     0.000000     0.315000     0.052000   \n",
       "max       4.385000     9.752000     4.081000    32.478000     6.003000   \n",
       "\n",
       "                53           54           55            56           57  \n",
       "count  4601.000000  4601.000000  4601.000000   4601.000000  4601.000000  \n",
       "mean      0.044238     5.191515    52.172789    283.289285     0.394045  \n",
       "std       0.429342    31.729449   194.891310    606.347851     0.488698  \n",
       "min       0.000000     1.000000     1.000000      1.000000     0.000000  \n",
       "25%       0.000000     1.588000     6.000000     35.000000     0.000000  \n",
       "50%       0.000000     2.276000    15.000000     95.000000     0.000000  \n",
       "75%       0.000000     3.706000    43.000000    266.000000     1.000000  \n",
       "max      19.829000  1102.500000  9989.000000  15841.000000     1.000000  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1813, 58)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[57] == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,:-1], df.iloc[:,-1], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort=False, random_state=0,\n",
       "                                              splitter='best'),\n",
       "             iid='warn', n_jobs=None, param_grid={'max_depth': [1, 20]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'max_depth':[1, 20]}\n",
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "clf = GridSearchCV(tree, parameters, cv=5)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mean_fit_time',\n",
       " 'mean_score_time',\n",
       " 'mean_test_score',\n",
       " 'param_max_depth',\n",
       " 'params',\n",
       " 'rank_test_score',\n",
       " 'split0_test_score',\n",
       " 'split1_test_score',\n",
       " 'split2_test_score',\n",
       " 'split3_test_score',\n",
       " 'split4_test_score',\n",
       " 'std_fit_time',\n",
       " 'std_score_time',\n",
       " 'std_test_score']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(clf.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=20,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=0, splitter='best')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': 8}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.826 (+/-0.037) for {'max_depth': 1}\n",
      "0.884 (+/-0.028) for {'max_depth': 2}\n",
      "0.874 (+/-0.020) for {'max_depth': 3}\n",
      "0.911 (+/-0.020) for {'max_depth': 4}\n",
      "0.909 (+/-0.015) for {'max_depth': 5}\n",
      "0.915 (+/-0.014) for {'max_depth': 6}\n",
      "0.913 (+/-0.013) for {'max_depth': 7}\n",
      "0.920 (+/-0.010) for {'max_depth': 8}\n",
      "0.920 (+/-0.016) for {'max_depth': 9}\n",
      "0.917 (+/-0.010) for {'max_depth': 10}\n",
      "0.917 (+/-0.011) for {'max_depth': 11}\n",
      "0.916 (+/-0.008) for {'max_depth': 12}\n",
      "0.912 (+/-0.012) for {'max_depth': 13}\n",
      "0.913 (+/-0.014) for {'max_depth': 14}\n",
      "0.913 (+/-0.012) for {'max_depth': 15}\n",
      "0.914 (+/-0.010) for {'max_depth': 16}\n",
      "0.919 (+/-0.019) for {'max_depth': 17}\n",
      "0.914 (+/-0.020) for {'max_depth': 18}\n",
      "0.914 (+/-0.013) for {'max_depth': 19}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93       531\n",
      "           1       0.94      0.86      0.90       390\n",
      "\n",
      "    accuracy                           0.92       921\n",
      "   macro avg       0.92      0.91      0.92       921\n",
      "weighted avg       0.92      0.92      0.92       921\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': 17}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.755 (+/-0.017) for {'max_depth': 1}\n",
      "0.840 (+/-0.026) for {'max_depth': 2}\n",
      "0.872 (+/-0.024) for {'max_depth': 3}\n",
      "0.883 (+/-0.031) for {'max_depth': 4}\n",
      "0.892 (+/-0.028) for {'max_depth': 5}\n",
      "0.900 (+/-0.032) for {'max_depth': 6}\n",
      "0.902 (+/-0.022) for {'max_depth': 7}\n",
      "0.908 (+/-0.021) for {'max_depth': 8}\n",
      "0.910 (+/-0.027) for {'max_depth': 9}\n",
      "0.909 (+/-0.024) for {'max_depth': 10}\n",
      "0.908 (+/-0.017) for {'max_depth': 11}\n",
      "0.910 (+/-0.019) for {'max_depth': 12}\n",
      "0.906 (+/-0.017) for {'max_depth': 13}\n",
      "0.908 (+/-0.019) for {'max_depth': 14}\n",
      "0.908 (+/-0.017) for {'max_depth': 15}\n",
      "0.908 (+/-0.015) for {'max_depth': 16}\n",
      "0.915 (+/-0.021) for {'max_depth': 17}\n",
      "0.911 (+/-0.024) for {'max_depth': 18}\n",
      "0.909 (+/-0.017) for {'max_depth': 19}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       531\n",
      "           1       0.92      0.86      0.89       390\n",
      "\n",
      "    accuracy                           0.91       921\n",
      "   macro avg       0.91      0.90      0.91       921\n",
      "weighted avg       0.91      0.91      0.91       921\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "parameters = {'max_depth':[x for x in range(1,20)]}\n",
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(tree, parameters, cv=5,\n",
    "                       scoring='%s_macro' % score)\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(x_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9174809989142236"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=8)\n",
    "clf = clf.fit(x_train, y_train)\n",
    "\n",
    "tree.export_graphviz(clf,out_file=\"tree.dot\") \n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': 16, 'n_estimators': 17}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.771 (+/-0.031) for {'max_depth': 1, 'n_estimators': 1}\n",
      "0.737 (+/-0.101) for {'max_depth': 1, 'n_estimators': 2}\n",
      "0.794 (+/-0.045) for {'max_depth': 1, 'n_estimators': 3}\n",
      "0.793 (+/-0.067) for {'max_depth': 1, 'n_estimators': 4}\n",
      "0.825 (+/-0.082) for {'max_depth': 1, 'n_estimators': 5}\n",
      "0.811 (+/-0.034) for {'max_depth': 1, 'n_estimators': 6}\n",
      "0.834 (+/-0.053) for {'max_depth': 1, 'n_estimators': 7}\n",
      "0.832 (+/-0.038) for {'max_depth': 1, 'n_estimators': 8}\n",
      "0.808 (+/-0.024) for {'max_depth': 1, 'n_estimators': 9}\n",
      "0.831 (+/-0.018) for {'max_depth': 1, 'n_estimators': 10}\n",
      "0.807 (+/-0.065) for {'max_depth': 1, 'n_estimators': 11}\n",
      "0.818 (+/-0.040) for {'max_depth': 1, 'n_estimators': 12}\n",
      "0.817 (+/-0.023) for {'max_depth': 1, 'n_estimators': 13}\n",
      "0.824 (+/-0.026) for {'max_depth': 1, 'n_estimators': 14}\n",
      "0.835 (+/-0.018) for {'max_depth': 1, 'n_estimators': 15}\n",
      "0.830 (+/-0.035) for {'max_depth': 1, 'n_estimators': 16}\n",
      "0.836 (+/-0.036) for {'max_depth': 1, 'n_estimators': 17}\n",
      "0.830 (+/-0.060) for {'max_depth': 1, 'n_estimators': 18}\n",
      "0.829 (+/-0.020) for {'max_depth': 1, 'n_estimators': 19}\n",
      "0.792 (+/-0.050) for {'max_depth': 2, 'n_estimators': 1}\n",
      "0.847 (+/-0.031) for {'max_depth': 2, 'n_estimators': 2}\n",
      "0.853 (+/-0.024) for {'max_depth': 2, 'n_estimators': 3}\n",
      "0.864 (+/-0.043) for {'max_depth': 2, 'n_estimators': 4}\n",
      "0.855 (+/-0.023) for {'max_depth': 2, 'n_estimators': 5}\n",
      "0.868 (+/-0.034) for {'max_depth': 2, 'n_estimators': 6}\n",
      "0.868 (+/-0.028) for {'max_depth': 2, 'n_estimators': 7}\n",
      "0.870 (+/-0.032) for {'max_depth': 2, 'n_estimators': 8}\n",
      "0.867 (+/-0.010) for {'max_depth': 2, 'n_estimators': 9}\n",
      "0.872 (+/-0.011) for {'max_depth': 2, 'n_estimators': 10}\n",
      "0.870 (+/-0.034) for {'max_depth': 2, 'n_estimators': 11}\n",
      "0.881 (+/-0.047) for {'max_depth': 2, 'n_estimators': 12}\n",
      "0.885 (+/-0.035) for {'max_depth': 2, 'n_estimators': 13}\n",
      "0.876 (+/-0.041) for {'max_depth': 2, 'n_estimators': 14}\n",
      "0.874 (+/-0.023) for {'max_depth': 2, 'n_estimators': 15}\n",
      "0.884 (+/-0.042) for {'max_depth': 2, 'n_estimators': 16}\n",
      "0.886 (+/-0.027) for {'max_depth': 2, 'n_estimators': 17}\n",
      "0.878 (+/-0.030) for {'max_depth': 2, 'n_estimators': 18}\n",
      "0.879 (+/-0.020) for {'max_depth': 2, 'n_estimators': 19}\n",
      "0.807 (+/-0.045) for {'max_depth': 3, 'n_estimators': 1}\n",
      "0.874 (+/-0.035) for {'max_depth': 3, 'n_estimators': 2}\n",
      "0.873 (+/-0.017) for {'max_depth': 3, 'n_estimators': 3}\n",
      "0.869 (+/-0.056) for {'max_depth': 3, 'n_estimators': 4}\n",
      "0.884 (+/-0.019) for {'max_depth': 3, 'n_estimators': 5}\n",
      "0.885 (+/-0.026) for {'max_depth': 3, 'n_estimators': 6}\n",
      "0.893 (+/-0.024) for {'max_depth': 3, 'n_estimators': 7}\n",
      "0.897 (+/-0.021) for {'max_depth': 3, 'n_estimators': 8}\n",
      "0.899 (+/-0.018) for {'max_depth': 3, 'n_estimators': 9}\n",
      "0.896 (+/-0.025) for {'max_depth': 3, 'n_estimators': 10}\n",
      "0.901 (+/-0.016) for {'max_depth': 3, 'n_estimators': 11}\n",
      "0.898 (+/-0.030) for {'max_depth': 3, 'n_estimators': 12}\n",
      "0.901 (+/-0.018) for {'max_depth': 3, 'n_estimators': 13}\n",
      "0.897 (+/-0.026) for {'max_depth': 3, 'n_estimators': 14}\n",
      "0.904 (+/-0.023) for {'max_depth': 3, 'n_estimators': 15}\n",
      "0.902 (+/-0.015) for {'max_depth': 3, 'n_estimators': 16}\n",
      "0.906 (+/-0.015) for {'max_depth': 3, 'n_estimators': 17}\n",
      "0.897 (+/-0.022) for {'max_depth': 3, 'n_estimators': 18}\n",
      "0.905 (+/-0.020) for {'max_depth': 3, 'n_estimators': 19}\n",
      "0.866 (+/-0.060) for {'max_depth': 4, 'n_estimators': 1}\n",
      "0.880 (+/-0.030) for {'max_depth': 4, 'n_estimators': 2}\n",
      "0.881 (+/-0.029) for {'max_depth': 4, 'n_estimators': 3}\n",
      "0.898 (+/-0.039) for {'max_depth': 4, 'n_estimators': 4}\n",
      "0.901 (+/-0.022) for {'max_depth': 4, 'n_estimators': 5}\n",
      "0.902 (+/-0.033) for {'max_depth': 4, 'n_estimators': 6}\n",
      "0.912 (+/-0.017) for {'max_depth': 4, 'n_estimators': 7}\n",
      "0.904 (+/-0.022) for {'max_depth': 4, 'n_estimators': 8}\n",
      "0.914 (+/-0.023) for {'max_depth': 4, 'n_estimators': 9}\n",
      "0.908 (+/-0.033) for {'max_depth': 4, 'n_estimators': 10}\n",
      "0.909 (+/-0.020) for {'max_depth': 4, 'n_estimators': 11}\n",
      "0.910 (+/-0.017) for {'max_depth': 4, 'n_estimators': 12}\n",
      "0.914 (+/-0.027) for {'max_depth': 4, 'n_estimators': 13}\n",
      "0.911 (+/-0.024) for {'max_depth': 4, 'n_estimators': 14}\n",
      "0.905 (+/-0.023) for {'max_depth': 4, 'n_estimators': 15}\n",
      "0.916 (+/-0.026) for {'max_depth': 4, 'n_estimators': 16}\n",
      "0.917 (+/-0.031) for {'max_depth': 4, 'n_estimators': 17}\n",
      "0.912 (+/-0.021) for {'max_depth': 4, 'n_estimators': 18}\n",
      "0.911 (+/-0.020) for {'max_depth': 4, 'n_estimators': 19}\n",
      "0.865 (+/-0.036) for {'max_depth': 5, 'n_estimators': 1}\n",
      "0.887 (+/-0.024) for {'max_depth': 5, 'n_estimators': 2}\n",
      "0.907 (+/-0.028) for {'max_depth': 5, 'n_estimators': 3}\n",
      "0.901 (+/-0.028) for {'max_depth': 5, 'n_estimators': 4}\n",
      "0.912 (+/-0.022) for {'max_depth': 5, 'n_estimators': 5}\n",
      "0.916 (+/-0.018) for {'max_depth': 5, 'n_estimators': 6}\n",
      "0.915 (+/-0.021) for {'max_depth': 5, 'n_estimators': 7}\n",
      "0.915 (+/-0.021) for {'max_depth': 5, 'n_estimators': 8}\n",
      "0.914 (+/-0.012) for {'max_depth': 5, 'n_estimators': 9}\n",
      "0.917 (+/-0.017) for {'max_depth': 5, 'n_estimators': 10}\n",
      "0.914 (+/-0.020) for {'max_depth': 5, 'n_estimators': 11}\n",
      "0.912 (+/-0.017) for {'max_depth': 5, 'n_estimators': 12}\n",
      "0.924 (+/-0.025) for {'max_depth': 5, 'n_estimators': 13}\n",
      "0.922 (+/-0.023) for {'max_depth': 5, 'n_estimators': 14}\n",
      "0.918 (+/-0.030) for {'max_depth': 5, 'n_estimators': 15}\n",
      "0.919 (+/-0.021) for {'max_depth': 5, 'n_estimators': 16}\n",
      "0.923 (+/-0.024) for {'max_depth': 5, 'n_estimators': 17}\n",
      "0.922 (+/-0.015) for {'max_depth': 5, 'n_estimators': 18}\n",
      "0.918 (+/-0.016) for {'max_depth': 5, 'n_estimators': 19}\n",
      "0.875 (+/-0.023) for {'max_depth': 6, 'n_estimators': 1}\n",
      "0.888 (+/-0.011) for {'max_depth': 6, 'n_estimators': 2}\n",
      "0.905 (+/-0.029) for {'max_depth': 6, 'n_estimators': 3}\n",
      "0.916 (+/-0.012) for {'max_depth': 6, 'n_estimators': 4}\n",
      "0.916 (+/-0.017) for {'max_depth': 6, 'n_estimators': 5}\n",
      "0.915 (+/-0.029) for {'max_depth': 6, 'n_estimators': 6}\n",
      "0.914 (+/-0.017) for {'max_depth': 6, 'n_estimators': 7}\n",
      "0.921 (+/-0.014) for {'max_depth': 6, 'n_estimators': 8}\n",
      "0.924 (+/-0.023) for {'max_depth': 6, 'n_estimators': 9}\n",
      "0.924 (+/-0.019) for {'max_depth': 6, 'n_estimators': 10}\n",
      "0.922 (+/-0.015) for {'max_depth': 6, 'n_estimators': 11}\n",
      "0.923 (+/-0.025) for {'max_depth': 6, 'n_estimators': 12}\n",
      "0.926 (+/-0.018) for {'max_depth': 6, 'n_estimators': 13}\n",
      "0.924 (+/-0.022) for {'max_depth': 6, 'n_estimators': 14}\n",
      "0.925 (+/-0.021) for {'max_depth': 6, 'n_estimators': 15}\n",
      "0.926 (+/-0.016) for {'max_depth': 6, 'n_estimators': 16}\n",
      "0.924 (+/-0.020) for {'max_depth': 6, 'n_estimators': 17}\n",
      "0.928 (+/-0.025) for {'max_depth': 6, 'n_estimators': 18}\n",
      "0.929 (+/-0.026) for {'max_depth': 6, 'n_estimators': 19}\n",
      "0.864 (+/-0.057) for {'max_depth': 7, 'n_estimators': 1}\n",
      "0.897 (+/-0.004) for {'max_depth': 7, 'n_estimators': 2}\n",
      "0.909 (+/-0.029) for {'max_depth': 7, 'n_estimators': 3}\n",
      "0.907 (+/-0.034) for {'max_depth': 7, 'n_estimators': 4}\n",
      "0.918 (+/-0.025) for {'max_depth': 7, 'n_estimators': 5}\n",
      "0.921 (+/-0.026) for {'max_depth': 7, 'n_estimators': 6}\n",
      "0.925 (+/-0.027) for {'max_depth': 7, 'n_estimators': 7}\n",
      "0.929 (+/-0.016) for {'max_depth': 7, 'n_estimators': 8}\n",
      "0.924 (+/-0.013) for {'max_depth': 7, 'n_estimators': 9}\n",
      "0.927 (+/-0.016) for {'max_depth': 7, 'n_estimators': 10}\n",
      "0.925 (+/-0.015) for {'max_depth': 7, 'n_estimators': 11}\n",
      "0.930 (+/-0.024) for {'max_depth': 7, 'n_estimators': 12}\n",
      "0.926 (+/-0.014) for {'max_depth': 7, 'n_estimators': 13}\n",
      "0.929 (+/-0.012) for {'max_depth': 7, 'n_estimators': 14}\n",
      "0.930 (+/-0.021) for {'max_depth': 7, 'n_estimators': 15}\n",
      "0.927 (+/-0.016) for {'max_depth': 7, 'n_estimators': 16}\n",
      "0.927 (+/-0.016) for {'max_depth': 7, 'n_estimators': 17}\n",
      "0.931 (+/-0.019) for {'max_depth': 7, 'n_estimators': 18}\n",
      "0.930 (+/-0.018) for {'max_depth': 7, 'n_estimators': 19}\n",
      "0.883 (+/-0.033) for {'max_depth': 8, 'n_estimators': 1}\n",
      "0.901 (+/-0.026) for {'max_depth': 8, 'n_estimators': 2}\n",
      "0.910 (+/-0.026) for {'max_depth': 8, 'n_estimators': 3}\n",
      "0.921 (+/-0.015) for {'max_depth': 8, 'n_estimators': 4}\n",
      "0.927 (+/-0.025) for {'max_depth': 8, 'n_estimators': 5}\n",
      "0.926 (+/-0.015) for {'max_depth': 8, 'n_estimators': 6}\n",
      "0.928 (+/-0.019) for {'max_depth': 8, 'n_estimators': 7}\n",
      "0.933 (+/-0.026) for {'max_depth': 8, 'n_estimators': 8}\n",
      "0.928 (+/-0.024) for {'max_depth': 8, 'n_estimators': 9}\n",
      "0.933 (+/-0.016) for {'max_depth': 8, 'n_estimators': 10}\n",
      "0.930 (+/-0.012) for {'max_depth': 8, 'n_estimators': 11}\n",
      "0.927 (+/-0.024) for {'max_depth': 8, 'n_estimators': 12}\n",
      "0.933 (+/-0.013) for {'max_depth': 8, 'n_estimators': 13}\n",
      "0.934 (+/-0.025) for {'max_depth': 8, 'n_estimators': 14}\n",
      "0.932 (+/-0.016) for {'max_depth': 8, 'n_estimators': 15}\n",
      "0.938 (+/-0.013) for {'max_depth': 8, 'n_estimators': 16}\n",
      "0.931 (+/-0.018) for {'max_depth': 8, 'n_estimators': 17}\n",
      "0.938 (+/-0.021) for {'max_depth': 8, 'n_estimators': 18}\n",
      "0.931 (+/-0.021) for {'max_depth': 8, 'n_estimators': 19}\n",
      "0.883 (+/-0.011) for {'max_depth': 9, 'n_estimators': 1}\n",
      "0.894 (+/-0.021) for {'max_depth': 9, 'n_estimators': 2}\n",
      "0.918 (+/-0.014) for {'max_depth': 9, 'n_estimators': 3}\n",
      "0.921 (+/-0.012) for {'max_depth': 9, 'n_estimators': 4}\n",
      "0.921 (+/-0.022) for {'max_depth': 9, 'n_estimators': 5}\n",
      "0.931 (+/-0.020) for {'max_depth': 9, 'n_estimators': 6}\n",
      "0.932 (+/-0.018) for {'max_depth': 9, 'n_estimators': 7}\n",
      "0.934 (+/-0.018) for {'max_depth': 9, 'n_estimators': 8}\n",
      "0.932 (+/-0.027) for {'max_depth': 9, 'n_estimators': 9}\n",
      "0.931 (+/-0.018) for {'max_depth': 9, 'n_estimators': 10}\n",
      "0.938 (+/-0.031) for {'max_depth': 9, 'n_estimators': 11}\n",
      "0.938 (+/-0.016) for {'max_depth': 9, 'n_estimators': 12}\n",
      "0.936 (+/-0.024) for {'max_depth': 9, 'n_estimators': 13}\n",
      "0.936 (+/-0.013) for {'max_depth': 9, 'n_estimators': 14}\n",
      "0.938 (+/-0.020) for {'max_depth': 9, 'n_estimators': 15}\n",
      "0.933 (+/-0.020) for {'max_depth': 9, 'n_estimators': 16}\n",
      "0.939 (+/-0.022) for {'max_depth': 9, 'n_estimators': 17}\n",
      "0.934 (+/-0.021) for {'max_depth': 9, 'n_estimators': 18}\n",
      "0.936 (+/-0.024) for {'max_depth': 9, 'n_estimators': 19}\n",
      "0.885 (+/-0.032) for {'max_depth': 10, 'n_estimators': 1}\n",
      "0.883 (+/-0.023) for {'max_depth': 10, 'n_estimators': 2}\n",
      "0.920 (+/-0.016) for {'max_depth': 10, 'n_estimators': 3}\n",
      "0.923 (+/-0.022) for {'max_depth': 10, 'n_estimators': 4}\n",
      "0.928 (+/-0.025) for {'max_depth': 10, 'n_estimators': 5}\n",
      "0.932 (+/-0.024) for {'max_depth': 10, 'n_estimators': 6}\n",
      "0.930 (+/-0.023) for {'max_depth': 10, 'n_estimators': 7}\n",
      "0.935 (+/-0.017) for {'max_depth': 10, 'n_estimators': 8}\n",
      "0.935 (+/-0.023) for {'max_depth': 10, 'n_estimators': 9}\n",
      "0.936 (+/-0.019) for {'max_depth': 10, 'n_estimators': 10}\n",
      "0.936 (+/-0.017) for {'max_depth': 10, 'n_estimators': 11}\n",
      "0.935 (+/-0.010) for {'max_depth': 10, 'n_estimators': 12}\n",
      "0.938 (+/-0.020) for {'max_depth': 10, 'n_estimators': 13}\n",
      "0.934 (+/-0.026) for {'max_depth': 10, 'n_estimators': 14}\n",
      "0.938 (+/-0.015) for {'max_depth': 10, 'n_estimators': 15}\n",
      "0.935 (+/-0.018) for {'max_depth': 10, 'n_estimators': 16}\n",
      "0.936 (+/-0.028) for {'max_depth': 10, 'n_estimators': 17}\n",
      "0.935 (+/-0.018) for {'max_depth': 10, 'n_estimators': 18}\n",
      "0.934 (+/-0.022) for {'max_depth': 10, 'n_estimators': 19}\n",
      "0.890 (+/-0.025) for {'max_depth': 11, 'n_estimators': 1}\n",
      "0.893 (+/-0.023) for {'max_depth': 11, 'n_estimators': 2}\n",
      "0.927 (+/-0.018) for {'max_depth': 11, 'n_estimators': 3}\n",
      "0.926 (+/-0.026) for {'max_depth': 11, 'n_estimators': 4}\n",
      "0.926 (+/-0.021) for {'max_depth': 11, 'n_estimators': 5}\n",
      "0.930 (+/-0.018) for {'max_depth': 11, 'n_estimators': 6}\n",
      "0.933 (+/-0.020) for {'max_depth': 11, 'n_estimators': 7}\n",
      "0.935 (+/-0.022) for {'max_depth': 11, 'n_estimators': 8}\n",
      "0.936 (+/-0.023) for {'max_depth': 11, 'n_estimators': 9}\n",
      "0.937 (+/-0.015) for {'max_depth': 11, 'n_estimators': 10}\n",
      "0.937 (+/-0.023) for {'max_depth': 11, 'n_estimators': 11}\n",
      "0.938 (+/-0.026) for {'max_depth': 11, 'n_estimators': 12}\n",
      "0.935 (+/-0.023) for {'max_depth': 11, 'n_estimators': 13}\n",
      "0.938 (+/-0.021) for {'max_depth': 11, 'n_estimators': 14}\n",
      "0.939 (+/-0.018) for {'max_depth': 11, 'n_estimators': 15}\n",
      "0.939 (+/-0.018) for {'max_depth': 11, 'n_estimators': 16}\n",
      "0.939 (+/-0.015) for {'max_depth': 11, 'n_estimators': 17}\n",
      "0.941 (+/-0.017) for {'max_depth': 11, 'n_estimators': 18}\n",
      "0.938 (+/-0.021) for {'max_depth': 11, 'n_estimators': 19}\n",
      "0.887 (+/-0.010) for {'max_depth': 12, 'n_estimators': 1}\n",
      "0.895 (+/-0.052) for {'max_depth': 12, 'n_estimators': 2}\n",
      "0.923 (+/-0.020) for {'max_depth': 12, 'n_estimators': 3}\n",
      "0.925 (+/-0.017) for {'max_depth': 12, 'n_estimators': 4}\n",
      "0.930 (+/-0.020) for {'max_depth': 12, 'n_estimators': 5}\n",
      "0.936 (+/-0.020) for {'max_depth': 12, 'n_estimators': 6}\n",
      "0.937 (+/-0.019) for {'max_depth': 12, 'n_estimators': 7}\n",
      "0.934 (+/-0.015) for {'max_depth': 12, 'n_estimators': 8}\n",
      "0.937 (+/-0.014) for {'max_depth': 12, 'n_estimators': 9}\n",
      "0.938 (+/-0.017) for {'max_depth': 12, 'n_estimators': 10}\n",
      "0.934 (+/-0.019) for {'max_depth': 12, 'n_estimators': 11}\n",
      "0.939 (+/-0.016) for {'max_depth': 12, 'n_estimators': 12}\n",
      "0.941 (+/-0.021) for {'max_depth': 12, 'n_estimators': 13}\n",
      "0.942 (+/-0.021) for {'max_depth': 12, 'n_estimators': 14}\n",
      "0.940 (+/-0.022) for {'max_depth': 12, 'n_estimators': 15}\n",
      "0.940 (+/-0.020) for {'max_depth': 12, 'n_estimators': 16}\n",
      "0.939 (+/-0.027) for {'max_depth': 12, 'n_estimators': 17}\n",
      "0.939 (+/-0.016) for {'max_depth': 12, 'n_estimators': 18}\n",
      "0.942 (+/-0.019) for {'max_depth': 12, 'n_estimators': 19}\n",
      "0.892 (+/-0.014) for {'max_depth': 13, 'n_estimators': 1}\n",
      "0.893 (+/-0.012) for {'max_depth': 13, 'n_estimators': 2}\n",
      "0.930 (+/-0.021) for {'max_depth': 13, 'n_estimators': 3}\n",
      "0.925 (+/-0.020) for {'max_depth': 13, 'n_estimators': 4}\n",
      "0.929 (+/-0.017) for {'max_depth': 13, 'n_estimators': 5}\n",
      "0.932 (+/-0.017) for {'max_depth': 13, 'n_estimators': 6}\n",
      "0.940 (+/-0.015) for {'max_depth': 13, 'n_estimators': 7}\n",
      "0.938 (+/-0.017) for {'max_depth': 13, 'n_estimators': 8}\n",
      "0.939 (+/-0.021) for {'max_depth': 13, 'n_estimators': 9}\n",
      "0.939 (+/-0.015) for {'max_depth': 13, 'n_estimators': 10}\n",
      "0.941 (+/-0.020) for {'max_depth': 13, 'n_estimators': 11}\n",
      "0.941 (+/-0.019) for {'max_depth': 13, 'n_estimators': 12}\n",
      "0.943 (+/-0.019) for {'max_depth': 13, 'n_estimators': 13}\n",
      "0.936 (+/-0.014) for {'max_depth': 13, 'n_estimators': 14}\n",
      "0.945 (+/-0.021) for {'max_depth': 13, 'n_estimators': 15}\n",
      "0.939 (+/-0.017) for {'max_depth': 13, 'n_estimators': 16}\n",
      "0.942 (+/-0.022) for {'max_depth': 13, 'n_estimators': 17}\n",
      "0.941 (+/-0.015) for {'max_depth': 13, 'n_estimators': 18}\n",
      "0.945 (+/-0.030) for {'max_depth': 13, 'n_estimators': 19}\n",
      "0.892 (+/-0.055) for {'max_depth': 14, 'n_estimators': 1}\n",
      "0.889 (+/-0.016) for {'max_depth': 14, 'n_estimators': 2}\n",
      "0.913 (+/-0.021) for {'max_depth': 14, 'n_estimators': 3}\n",
      "0.921 (+/-0.015) for {'max_depth': 14, 'n_estimators': 4}\n",
      "0.936 (+/-0.024) for {'max_depth': 14, 'n_estimators': 5}\n",
      "0.932 (+/-0.016) for {'max_depth': 14, 'n_estimators': 6}\n",
      "0.936 (+/-0.034) for {'max_depth': 14, 'n_estimators': 7}\n",
      "0.938 (+/-0.012) for {'max_depth': 14, 'n_estimators': 8}\n",
      "0.939 (+/-0.019) for {'max_depth': 14, 'n_estimators': 9}\n",
      "0.939 (+/-0.022) for {'max_depth': 14, 'n_estimators': 10}\n",
      "0.940 (+/-0.024) for {'max_depth': 14, 'n_estimators': 11}\n",
      "0.946 (+/-0.023) for {'max_depth': 14, 'n_estimators': 12}\n",
      "0.941 (+/-0.018) for {'max_depth': 14, 'n_estimators': 13}\n",
      "0.942 (+/-0.020) for {'max_depth': 14, 'n_estimators': 14}\n",
      "0.940 (+/-0.020) for {'max_depth': 14, 'n_estimators': 15}\n",
      "0.943 (+/-0.027) for {'max_depth': 14, 'n_estimators': 16}\n",
      "0.942 (+/-0.018) for {'max_depth': 14, 'n_estimators': 17}\n",
      "0.942 (+/-0.022) for {'max_depth': 14, 'n_estimators': 18}\n",
      "0.941 (+/-0.028) for {'max_depth': 14, 'n_estimators': 19}\n",
      "0.890 (+/-0.018) for {'max_depth': 15, 'n_estimators': 1}\n",
      "0.887 (+/-0.013) for {'max_depth': 15, 'n_estimators': 2}\n",
      "0.915 (+/-0.027) for {'max_depth': 15, 'n_estimators': 3}\n",
      "0.922 (+/-0.017) for {'max_depth': 15, 'n_estimators': 4}\n",
      "0.928 (+/-0.020) for {'max_depth': 15, 'n_estimators': 5}\n",
      "0.930 (+/-0.027) for {'max_depth': 15, 'n_estimators': 6}\n",
      "0.936 (+/-0.030) for {'max_depth': 15, 'n_estimators': 7}\n",
      "0.938 (+/-0.018) for {'max_depth': 15, 'n_estimators': 8}\n",
      "0.936 (+/-0.031) for {'max_depth': 15, 'n_estimators': 9}\n",
      "0.937 (+/-0.025) for {'max_depth': 15, 'n_estimators': 10}\n",
      "0.942 (+/-0.020) for {'max_depth': 15, 'n_estimators': 11}\n",
      "0.942 (+/-0.017) for {'max_depth': 15, 'n_estimators': 12}\n",
      "0.938 (+/-0.016) for {'max_depth': 15, 'n_estimators': 13}\n",
      "0.945 (+/-0.012) for {'max_depth': 15, 'n_estimators': 14}\n",
      "0.942 (+/-0.020) for {'max_depth': 15, 'n_estimators': 15}\n",
      "0.948 (+/-0.011) for {'max_depth': 15, 'n_estimators': 16}\n",
      "0.942 (+/-0.018) for {'max_depth': 15, 'n_estimators': 17}\n",
      "0.945 (+/-0.020) for {'max_depth': 15, 'n_estimators': 18}\n",
      "0.943 (+/-0.026) for {'max_depth': 15, 'n_estimators': 19}\n",
      "0.887 (+/-0.020) for {'max_depth': 16, 'n_estimators': 1}\n",
      "0.899 (+/-0.015) for {'max_depth': 16, 'n_estimators': 2}\n",
      "0.923 (+/-0.031) for {'max_depth': 16, 'n_estimators': 3}\n",
      "0.925 (+/-0.015) for {'max_depth': 16, 'n_estimators': 4}\n",
      "0.931 (+/-0.020) for {'max_depth': 16, 'n_estimators': 5}\n",
      "0.934 (+/-0.017) for {'max_depth': 16, 'n_estimators': 6}\n",
      "0.937 (+/-0.020) for {'max_depth': 16, 'n_estimators': 7}\n",
      "0.934 (+/-0.019) for {'max_depth': 16, 'n_estimators': 8}\n",
      "0.935 (+/-0.020) for {'max_depth': 16, 'n_estimators': 9}\n",
      "0.941 (+/-0.016) for {'max_depth': 16, 'n_estimators': 10}\n",
      "0.939 (+/-0.020) for {'max_depth': 16, 'n_estimators': 11}\n",
      "0.941 (+/-0.012) for {'max_depth': 16, 'n_estimators': 12}\n",
      "0.942 (+/-0.019) for {'max_depth': 16, 'n_estimators': 13}\n",
      "0.944 (+/-0.016) for {'max_depth': 16, 'n_estimators': 14}\n",
      "0.946 (+/-0.015) for {'max_depth': 16, 'n_estimators': 15}\n",
      "0.944 (+/-0.021) for {'max_depth': 16, 'n_estimators': 16}\n",
      "0.951 (+/-0.017) for {'max_depth': 16, 'n_estimators': 17}\n",
      "0.944 (+/-0.023) for {'max_depth': 16, 'n_estimators': 18}\n",
      "0.945 (+/-0.030) for {'max_depth': 16, 'n_estimators': 19}\n",
      "0.886 (+/-0.023) for {'max_depth': 17, 'n_estimators': 1}\n",
      "0.896 (+/-0.025) for {'max_depth': 17, 'n_estimators': 2}\n",
      "0.923 (+/-0.017) for {'max_depth': 17, 'n_estimators': 3}\n",
      "0.924 (+/-0.020) for {'max_depth': 17, 'n_estimators': 4}\n",
      "0.933 (+/-0.024) for {'max_depth': 17, 'n_estimators': 5}\n",
      "0.934 (+/-0.031) for {'max_depth': 17, 'n_estimators': 6}\n",
      "0.939 (+/-0.028) for {'max_depth': 17, 'n_estimators': 7}\n",
      "0.934 (+/-0.022) for {'max_depth': 17, 'n_estimators': 8}\n",
      "0.935 (+/-0.027) for {'max_depth': 17, 'n_estimators': 9}\n",
      "0.939 (+/-0.010) for {'max_depth': 17, 'n_estimators': 10}\n",
      "0.939 (+/-0.018) for {'max_depth': 17, 'n_estimators': 11}\n",
      "0.940 (+/-0.021) for {'max_depth': 17, 'n_estimators': 12}\n",
      "0.942 (+/-0.015) for {'max_depth': 17, 'n_estimators': 13}\n",
      "0.941 (+/-0.026) for {'max_depth': 17, 'n_estimators': 14}\n",
      "0.945 (+/-0.021) for {'max_depth': 17, 'n_estimators': 15}\n",
      "0.945 (+/-0.019) for {'max_depth': 17, 'n_estimators': 16}\n",
      "0.945 (+/-0.019) for {'max_depth': 17, 'n_estimators': 17}\n",
      "0.945 (+/-0.022) for {'max_depth': 17, 'n_estimators': 18}\n",
      "0.945 (+/-0.022) for {'max_depth': 17, 'n_estimators': 19}\n",
      "0.901 (+/-0.024) for {'max_depth': 18, 'n_estimators': 1}\n",
      "0.892 (+/-0.015) for {'max_depth': 18, 'n_estimators': 2}\n",
      "0.917 (+/-0.021) for {'max_depth': 18, 'n_estimators': 3}\n",
      "0.922 (+/-0.012) for {'max_depth': 18, 'n_estimators': 4}\n",
      "0.933 (+/-0.020) for {'max_depth': 18, 'n_estimators': 5}\n",
      "0.934 (+/-0.018) for {'max_depth': 18, 'n_estimators': 6}\n",
      "0.930 (+/-0.023) for {'max_depth': 18, 'n_estimators': 7}\n",
      "0.938 (+/-0.022) for {'max_depth': 18, 'n_estimators': 8}\n",
      "0.942 (+/-0.029) for {'max_depth': 18, 'n_estimators': 9}\n",
      "0.943 (+/-0.021) for {'max_depth': 18, 'n_estimators': 10}\n",
      "0.942 (+/-0.017) for {'max_depth': 18, 'n_estimators': 11}\n",
      "0.940 (+/-0.020) for {'max_depth': 18, 'n_estimators': 12}\n",
      "0.939 (+/-0.020) for {'max_depth': 18, 'n_estimators': 13}\n",
      "0.945 (+/-0.017) for {'max_depth': 18, 'n_estimators': 14}\n",
      "0.943 (+/-0.014) for {'max_depth': 18, 'n_estimators': 15}\n",
      "0.945 (+/-0.015) for {'max_depth': 18, 'n_estimators': 16}\n",
      "0.946 (+/-0.018) for {'max_depth': 18, 'n_estimators': 17}\n",
      "0.944 (+/-0.021) for {'max_depth': 18, 'n_estimators': 18}\n",
      "0.945 (+/-0.022) for {'max_depth': 18, 'n_estimators': 19}\n",
      "0.886 (+/-0.019) for {'max_depth': 19, 'n_estimators': 1}\n",
      "0.894 (+/-0.019) for {'max_depth': 19, 'n_estimators': 2}\n",
      "0.924 (+/-0.028) for {'max_depth': 19, 'n_estimators': 3}\n",
      "0.918 (+/-0.020) for {'max_depth': 19, 'n_estimators': 4}\n",
      "0.936 (+/-0.023) for {'max_depth': 19, 'n_estimators': 5}\n",
      "0.932 (+/-0.011) for {'max_depth': 19, 'n_estimators': 6}\n",
      "0.936 (+/-0.022) for {'max_depth': 19, 'n_estimators': 7}\n",
      "0.941 (+/-0.023) for {'max_depth': 19, 'n_estimators': 8}\n",
      "0.940 (+/-0.016) for {'max_depth': 19, 'n_estimators': 9}\n",
      "0.942 (+/-0.020) for {'max_depth': 19, 'n_estimators': 10}\n",
      "0.940 (+/-0.028) for {'max_depth': 19, 'n_estimators': 11}\n",
      "0.942 (+/-0.028) for {'max_depth': 19, 'n_estimators': 12}\n",
      "0.944 (+/-0.014) for {'max_depth': 19, 'n_estimators': 13}\n",
      "0.944 (+/-0.017) for {'max_depth': 19, 'n_estimators': 14}\n",
      "0.946 (+/-0.022) for {'max_depth': 19, 'n_estimators': 15}\n",
      "0.944 (+/-0.018) for {'max_depth': 19, 'n_estimators': 16}\n",
      "0.944 (+/-0.024) for {'max_depth': 19, 'n_estimators': 17}\n",
      "0.945 (+/-0.022) for {'max_depth': 19, 'n_estimators': 18}\n",
      "0.944 (+/-0.021) for {'max_depth': 19, 'n_estimators': 19}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       531\n",
      "           1       0.97      0.91      0.94       390\n",
      "\n",
      "    accuracy                           0.95       921\n",
      "   macro avg       0.96      0.95      0.95       921\n",
      "weighted avg       0.95      0.95      0.95       921\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=8, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "parameters = {'max_depth':[x for x in range(1,20)], \"n_estimators\":[x for x in range(20,50)]}\n",
    "tree = RandomForestClassifier()\n",
    "scores = [\"accuracy\"]\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(tree, parameters, cv=5,\n",
    "                       scoring=score)\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(x_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "#todo split datause for confusion matrix\n",
    "def rand_search(clf, param_dist, x, y, cv=5, n_iter_search=20):\n",
    "    x, x_test, y, y_test = train_test_split(x, y, test_size=0.05, random_state=42)\n",
    "    \n",
    "    random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search, cv=cv, iid=False)\n",
    "    start = time()\n",
    "    random_search.fit(x, y)\n",
    "    print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "          \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "    report(random_search.cv_results_)\n",
    "    results = random_search.cv_results_\n",
    "    y_pred = random_search.predict(x_test)\n",
    "    cm = confusion_matrix(list(y_test), list(y_pred))\n",
    "    return {\"results\":results,\"confusion_matrix\":cm}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 50.41 seconds for 20 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.948 (std: 0.007)\n",
      "Parameters: {'n_estimators': 308, 'max_depth': 19}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.946 (std: 0.004)\n",
      "Parameters: {'n_estimators': 469, 'max_depth': 16}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.945 (std: 0.005)\n",
      "Parameters: {'n_estimators': 418, 'max_depth': 16}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'results': {'mean_fit_time': array([0.04394946, 1.08537126, 0.18918571, 0.87052703, 0.34723525,\n",
       "         0.15368171, 0.72506113, 0.10014091, 0.6235642 , 0.29786763,\n",
       "         0.88814721, 0.02572255, 0.98788953, 0.03324485, 0.24177723,\n",
       "         0.42300305, 0.88877974, 0.84461451, 0.10340734, 0.60727844]),\n",
       "  'std_fit_time': array([0.00501764, 0.01800868, 0.00289252, 0.00744315, 0.0031674 ,\n",
       "         0.00156562, 0.00569641, 0.00115541, 0.00540853, 0.00311124,\n",
       "         0.02238096, 0.00080072, 0.01987097, 0.00155167, 0.00997054,\n",
       "         0.00616473, 0.00967504, 0.01379255, 0.00173449, 0.00678847]),\n",
       "  'mean_score_time': array([0.00276823, 0.04403553, 0.00816083, 0.03457093, 0.01485057,\n",
       "         0.01295738, 0.02904377, 0.00540323, 0.03038568, 0.01331429,\n",
       "         0.03657632, 0.00250726, 0.03945537, 0.00315032, 0.01519895,\n",
       "         0.01719494, 0.03544555, 0.03428006, 0.0077352 , 0.02453089]),\n",
       "  'std_score_time': array([4.52046656e-05, 3.34965568e-03, 2.10354917e-05, 5.48456827e-04,\n",
       "         1.79778764e-04, 3.59589423e-04, 3.15764238e-04, 5.55879244e-05,\n",
       "         2.56356960e-04, 1.00419392e-04, 2.74493169e-03, 4.49709267e-05,\n",
       "         7.36502836e-04, 2.89782913e-04, 8.64432096e-04, 1.08220333e-04,\n",
       "         4.47309056e-04, 5.86574927e-04, 3.13353980e-04, 6.62254631e-04]),\n",
       "  'param_n_estimators': masked_array(data=[23, 469, 84, 375, 178, 209, 308, 64, 438, 164, 417, 26,\n",
       "                     418, 33, 211, 182, 391, 416, 111, 277],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_max_depth': masked_array(data=[7, 16, 14, 18, 9, 1, 19, 6, 5, 8, 11, 2, 16, 2, 3, 16,\n",
       "                     15, 10, 2, 13],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'n_estimators': 23, 'max_depth': 7},\n",
       "   {'n_estimators': 469, 'max_depth': 16},\n",
       "   {'n_estimators': 84, 'max_depth': 14},\n",
       "   {'n_estimators': 375, 'max_depth': 18},\n",
       "   {'n_estimators': 178, 'max_depth': 9},\n",
       "   {'n_estimators': 209, 'max_depth': 1},\n",
       "   {'n_estimators': 308, 'max_depth': 19},\n",
       "   {'n_estimators': 64, 'max_depth': 6},\n",
       "   {'n_estimators': 438, 'max_depth': 5},\n",
       "   {'n_estimators': 164, 'max_depth': 8},\n",
       "   {'n_estimators': 417, 'max_depth': 11},\n",
       "   {'n_estimators': 26, 'max_depth': 2},\n",
       "   {'n_estimators': 418, 'max_depth': 16},\n",
       "   {'n_estimators': 33, 'max_depth': 2},\n",
       "   {'n_estimators': 211, 'max_depth': 3},\n",
       "   {'n_estimators': 182, 'max_depth': 16},\n",
       "   {'n_estimators': 391, 'max_depth': 15},\n",
       "   {'n_estimators': 416, 'max_depth': 10},\n",
       "   {'n_estimators': 111, 'max_depth': 2},\n",
       "   {'n_estimators': 277, 'max_depth': 13}],\n",
       "  'split0_test_score': array([0.93142857, 0.95285714, 0.94857143, 0.95285714, 0.94142857,\n",
       "         0.85857143, 0.95428571, 0.92571429, 0.92142857, 0.94      ,\n",
       "         0.94571429, 0.89571429, 0.95142857, 0.88714286, 0.90571429,\n",
       "         0.95142857, 0.95      , 0.94571429, 0.89142857, 0.94857143]),\n",
       "  'split1_test_score': array([0.93714286, 0.94571429, 0.94      , 0.94142857, 0.93571429,\n",
       "         0.84      , 0.94571429, 0.93714286, 0.93      , 0.93571429,\n",
       "         0.93428571, 0.89142857, 0.94142857, 0.89428571, 0.91285714,\n",
       "         0.94285714, 0.94142857, 0.93571429, 0.90142857, 0.93857143]),\n",
       "  'split2_test_score': array([0.94134478, 0.94420601, 0.94706724, 0.94706724, 0.94849785,\n",
       "         0.82403433, 0.9527897 , 0.93562232, 0.93562232, 0.94706724,\n",
       "         0.94706724, 0.88555079, 0.94992847, 0.89270386, 0.91559371,\n",
       "         0.94563662, 0.94563662, 0.94563662, 0.89127325, 0.94563662]),\n",
       "  'split3_test_score': array([0.92989986, 0.93991416, 0.93991416, 0.93133047, 0.93276109,\n",
       "         0.80829757, 0.93562232, 0.91702432, 0.91702432, 0.93276109,\n",
       "         0.93562232, 0.8869814 , 0.93848355, 0.88841202, 0.89985694,\n",
       "         0.93562232, 0.93848355, 0.93562232, 0.8769671 , 0.93133047]),\n",
       "  'split4_test_score': array([0.9269341 , 0.94555874, 0.94555874, 0.94555874, 0.93266476,\n",
       "         0.84813754, 0.9512894 , 0.9269341 , 0.92406877, 0.93409742,\n",
       "         0.94269341, 0.88252149, 0.94555874, 0.88538682, 0.90544413,\n",
       "         0.94412607, 0.94126074, 0.93839542, 0.88681948, 0.94555874]),\n",
       "  'mean_test_score': array([0.93335003, 0.94565007, 0.94422231, 0.94364843, 0.93821331,\n",
       "         0.83580817, 0.94794028, 0.92848758, 0.9256288 , 0.93792801,\n",
       "         0.94107659, 0.88843931, 0.94536558, 0.88958625, 0.90789324,\n",
       "         0.94393415, 0.9433619 , 0.94021659, 0.88958339, 0.94193374]),\n",
       "  'std_test_score': array([0.00519733, 0.0041699 , 0.00361061, 0.00716656, 0.00604761,\n",
       "         0.01779442, 0.00680713, 0.00731203, 0.00652825, 0.0051786 ,\n",
       "         0.00521297, 0.00463359, 0.00490876, 0.00337012, 0.00564386,\n",
       "         0.00508622, 0.00402963, 0.00456719, 0.0079168 , 0.00623932]),\n",
       "  'rank_test_score': array([13,  2,  4,  6, 11, 20,  1, 14, 15, 12,  9, 19,  3, 17, 16,  5,  7,\n",
       "         10, 18,  8], dtype=int32)},\n",
       " 'confusion_matrix': array([[96,  4],\n",
       "        [ 7, 77]])}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "\n",
    "parameters = {'max_depth':[x for x in range(1,20)], \"n_estimators\":[x for x in range(20,500)]}\n",
    "\n",
    "rand_search(clf, parameters, x_train, y_train, cv=5, n_iter_search=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9109952194697958\n",
      "0.9486165435317977\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=0, max_depth = 8).fit(x_train, y_train)\n",
    "y_pred = tree.predict(x_test)\n",
    "\n",
    "auc_tree = roc_auc_score(y_test, y_pred)\n",
    "print(auc_tree)\n",
    "\n",
    "\n",
    "r_tree = RandomForestClassifier(random_state=0, max_depth = 17, n_estimators=121).fit(x_train, y_train)\n",
    "y_pred = r_tree.predict(x_test)\n",
    "\n",
    "auc_tree = roc_auc_score(y_test, y_pred)\n",
    "print(auc_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc= []\n",
    "\n",
    "for i in range (1,301):\n",
    "    r_tree = RandomForestClassifier(random_state=0, max_depth = 10, n_estimators=i).fit(x_train, y_train)\n",
    "    y_pred = r_tree.predict(x_test)\n",
    "    auc_tree = roc_auc_score(y_test, y_pred)\n",
    "    auc.append(auc_tree)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.DataFrame(auc, columns =['auc'])\n",
    "\n",
    "ax = sns.lineplot( data=df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"q2/copper-new.txt\",  header = None)\n",
    "df.head"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
