{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jfftilton/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/jfftilton/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data.dat', sep=\"   \", header=None).to_numpy().T\n",
    "lab = pd.read_csv('label.dat', sep=\"   \", header=None).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization(X, K):\n",
    "    m,n=X.shape\n",
    "    pis = np.random.dirichlet(np.ones(K),size=1).reshape(K)\n",
    "    \n",
    "    idx = np.random.randint(n, size=n)\n",
    "    mus = np.zeros(shape=(K,n))\n",
    "    for k in range(K):\n",
    "        idx = np.random.randint(m, size=int(m/K))\n",
    "        x = X[idx]\n",
    "        mu = x.mean(axis=0)\n",
    "        mus[k] = mu\n",
    "    sigmas = np.array([np.identity(n)]*K)\n",
    "    return pis, mus, sigmas\n",
    "\n",
    "\n",
    "def get_mus(X,expectations):\n",
    "    n,m=X.shape\n",
    "    K = expectations.shape[1]\n",
    "    mus = np.zeros(shape=(K,m))\n",
    "    for k in range(K):\n",
    "        tau = expectations[:,k]\n",
    "        numerator = np.zeros(shape=(m))\n",
    "        for i in range(n):\n",
    "            x_i=X[i,:]\n",
    "            tau_i = tau[i]\n",
    "            numerator += tau_i * x_i\n",
    "        mu = numerator / np.sum(tau)\n",
    "        mus[k] = mu\n",
    "    return mus\n",
    "\n",
    "\n",
    "def get_sigmas(X,expectations,mus):\n",
    "    n,m=X.shape\n",
    "    K = expectations.shape[1]\n",
    "    sigmas = np.zeros((K, m, m))\n",
    "    for k in range(K):\n",
    "        tau = expectations[:,k]\n",
    "        mu = mus[k,:]\n",
    "        numerator = np.zeros(shape=(m,m))\n",
    "        for i in range(n):\n",
    "            x_i=X[i,:]\n",
    "            tau_i = tau[i]\n",
    "            x_i_minus_mu = (x_i - mu).reshape(m,1)\n",
    "            numerator += tau_i*np.dot(x_i_minus_mu,x_i_minus_mu.T)\n",
    "        sigmas[k] = numerator / np.sum(tau)\n",
    "            \n",
    "    return sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:5,:]\n",
    "pis, mus, sigmas = initialization(X, K)\n",
    "max_iter = 100\n",
    "r=50\n",
    "\n",
    "log_likelihood = []\n",
    "for m in range(max_iter):\n",
    "    K = 2\n",
    "    m,n=X.shape\n",
    "    ll = 0\n",
    "    Es = np.zeros(shape=(m,K))\n",
    "    Ns = np.zeros(shape=(m,K))\n",
    "    for k in range(K):\n",
    "        mu_k = mus[k,:]\n",
    "        pi_k = pis[k]\n",
    "        sigma_k = sigmas[k,:,:]\n",
    "        exponents = np.zeros(shape=(m))\n",
    "        N = np.zeros(shape=(m))\n",
    "        for i in range(m):\n",
    "            x = X[i,:]\n",
    "            # decomposition\n",
    "            e_val, e_vec = np.linalg.eigh(sigma_k)\n",
    "            #order eigenvalue/vectors in descending order\n",
    "            idx = np.argsort(e_val)[::-1]\n",
    "            e_val = e_val[idx]\n",
    "            e_vec = e_vec[:,idx]\n",
    "\n",
    "            #threshold\n",
    "            e_val = e_val[:r]\n",
    "            e_vec = e_vec[:,:r]\n",
    "\n",
    "            # Low rank approximation of values \n",
    "            sigma_approx = np.dot(np.dot(e_vec,np.diag(e_val**-1)),e_vec.T)\n",
    "            mu_approx = np.dot(e_vec.T,mu)\n",
    "            x_approx = np.dot(e_vec.T,x)\n",
    "            x_approx_minus_mu_approx = x_approx - mu_approx\n",
    "            exponent = np.exp(-.5 * np.sum((x_approx_minus_mu_approx**2) / e_val))\n",
    "            denominator = np.sqrt(np.prod(e_val))\n",
    "            ll += np.log(exponent) + np.log(denominator)\n",
    "            exponents[i] = exponent\n",
    "            en = exponent / denominator\n",
    "            N[i] = en\n",
    "        Es[:,k] = exponents\n",
    "        Ns[:,k] = N\n",
    "    log_likelihood.append(ll)\n",
    "    print(ll)\n",
    "    taus = Ns / np.sum(Ns)\n",
    "    mus = get_mus(X,taus)\n",
    "    pis = np.zeros(shape=(K))\n",
    "    sigmas = get_sigmas(X,taus,mus)\n",
    "    for k in range(K):\n",
    "        tau_k = taus[:,k]\n",
    "        pi_k = np.sum(tau_k) / m\n",
    "        pis[k] = pi_k\n",
    "    \n",
    "        \n",
    "       \n",
    "    \n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_approximations(x, mu, sigma, r=50):\n",
    "    m,d = X.shape\n",
    "    w,v = np.linalg.eigh(sigma)\n",
    "    idx = np.argsort(w)[::-1]\n",
    "    little_lam = w[:r]\n",
    "    lambd = np.diag(little_lam**-1)\n",
    "    U = v[:,:r]\n",
    "    sigma_approx = np.dot(np.dot(U,lambd), U.T)\n",
    "    mu_approx = np.dot(U.T, mu.reshape(d))\n",
    "    x_approx = np.dot(U.T, x)\n",
    "    return x_approx, mu_approx, sigma_approx, lambd, little_lam\n",
    "\n",
    "def get_n_parts(x, mu, sigma, r=50):\n",
    "    x_approx, mu_approx, sigma_approx, lambd, little_lam = get_approximations(x, mu, sigma, r=r)\n",
    "    xm = x_approx-mu_approx\n",
    "    denominator = np.prod(little_lam)\n",
    "    likelihood = np.exp(np.dot(np.dot(xm.T,lambd), xm) * -.5)\n",
    "    return likelihood, denominator\n",
    "\n",
    "\n",
    "def get_mus(X,expectations):\n",
    "    n,m=X.shape\n",
    "    K = expectations.shape[1]\n",
    "    mus = np.zeros(shape=(K,m))\n",
    "    for k in range(K):\n",
    "        tau = expectations[:,k]\n",
    "        numerator = np.zeros(shape=(m))\n",
    "        for i in range(n):\n",
    "            x_i=X[i,:]\n",
    "            tau_i = tau[i]\n",
    "            numerator += tau_i * x_i\n",
    "        mu = numerator / np.sum(tau)\n",
    "        mus[k] = mu\n",
    "    return mus\n",
    "\n",
    "def get_sigmas(X,expectations,mus):\n",
    "    n,m=X.shape\n",
    "    K = expectations.shape[1]\n",
    "    sigmas = np.zeros((K, m, m))\n",
    "    for k in range(K):\n",
    "        tau = expectations[:,k]\n",
    "        mu = mus[k,:]\n",
    "        numerator = np.zeros(shape=(m,m))\n",
    "        for i in range(n):\n",
    "            x_i=X[i,:]\n",
    "            tau_i = tau[i]\n",
    "            x_i_minus_mu = (x_i - mu).reshape(m,1)\n",
    "            numerator += tau_i*np.dot(x_i_minus_mu,x_i_minus_mu.T)\n",
    "        sigmas[k] = numerator / np.sum(tau)\n",
    "            \n",
    "    return sigmas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "X = data[:100,:]\n",
    "K = 2\n",
    "pis, mus, sigmas = initialization(X, K)\n",
    "m,d = X.shape\n",
    "max_iter = 10\n",
    "log_likelihoods = []\n",
    "for z in range(max_iter):\n",
    "    N = np.zeros(shape=(m, K))\n",
    "    taus = np.zeros(shape=(m, K))\n",
    "    k = 0\n",
    "    log_likelihood = 0\n",
    "    # e part\n",
    "    for pi, mu, sigma in zip(pis,mus, sigmas):\n",
    "        n_parts = np.apply_along_axis(get_n_parts, 1, X, mu, sigma, r=50)\n",
    "        n = n_parts[:,0] / n_parts[:,1]\n",
    "        tau = n * pi\n",
    "        log_likelihood += np.sum(np.log(n_parts[:,0]))\n",
    "        N[:,k] = n\n",
    "        taus[:,k] = tau\n",
    "        k+=1\n",
    "    taus_sum = taus.sum(axis = 1)\n",
    "    taus = np.array([taus[:,0]/taus_sum, taus[:,1]/taus_sum]).reshape(m,k)\n",
    "    # m part\n",
    "    pis = taus.sum(axis=0) / m\n",
    "    mus = get_mus(X,taus)\n",
    "    sigmas = get_sigmas(X,taus,mus)\n",
    "    log_likelihoods.append(log_likelihood)\n",
    "    print(log_likelihood)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-6fbf37336a40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtau\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[1;32m     34\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[1;32m     35\u001b[0m          initial=_NoValue):\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
