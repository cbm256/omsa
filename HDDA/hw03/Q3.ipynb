{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from scipy.io import loadmat\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorly\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorly.decomposition import tucker\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = [x[0] for x in loadmat('train_lab.mat')[\"train\"]] \n",
    "y_test = [x[0] for x in loadmat('test_lab.mat')[\"test\"]]\n",
    "\n",
    "train_files = glob.glob('CatsBirds/train*')\n",
    "test_files = glob.glob('CatsBirds/Test*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 500)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(Image.open(train_files[0]).convert('L')).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 1\n",
    "tnsr_train = np.zeros((500,500,len(train_files)))\n",
    "tnsr_test = np.zeros((500,500,len(test_files)))\n",
    "\n",
    "\n",
    "for tf in train_files:\n",
    "    idx = int(tf.split(\"train\")[1].split(\".\")[0]) - 1\n",
    "    tnsr_train[:,:,idx] = np.array(Image.open(tf).convert('L'))\n",
    "    \n",
    "for tf in test_files:\n",
    "    idx = int(tf.split(\"Test\")[1].split(\".\")[0]) - 1\n",
    "    tnsr_test[:,:,idx] = np.array(Image.open(tf).convert('L'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#partial decomposition\n",
    "G, factors = tensorly.decomposition.partial_tucker(tnsr_train, modes = [0,1],ranks=[10,10,len(train_files)])\n",
    "\n",
    "A,B =factors\n",
    "\n",
    "G_f = np.zeros((28,100))\n",
    "for i in range(28):\n",
    "    G_f[i] = G[:,:,i].flatten()\n",
    "    \n",
    "G_test = tensorly.tenalg.multi_mode_dot(tnsr_test, [x.T for x in factors], modes=[0,1])\n",
    "\n",
    "G_test_f = np.zeros((12,100))\n",
    "for i in range(12):\n",
    "    G_test_f[i] = G_test[:,:,i].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08333333333333337"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=2,n_estimators=100)\n",
    "clf.fit(G_f, y_train)\n",
    "y_hat = clf.predict(G_test_f)\n",
    "# error rate\n",
    "1-accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 2\n",
    "tnsr_train = np.zeros((500,500,3,len(train_files)))\n",
    "tnsr_test = np.zeros((500,500,3,len(test_files)))\n",
    "\n",
    "for tf in train_files:\n",
    "    idx = int(tf.split(\"train\")[1].split(\".\")[0]) - 1\n",
    "    tnsr_train[:,:,:,idx] = np.array(Image.open(tf))\n",
    "    \n",
    "for tf in test_files:\n",
    "    idx = int(tf.split(\"Test\")[1].split(\".\")[0]) - 1\n",
    "    tnsr_test[:,:,:,idx] = np.array(Image.open(tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#partial decomposition\n",
    "G, factors = tensorly.decomposition.partial_tucker(tnsr_train, modes = [0,1,2],ranks=[10,10,3,len(train_files)])\n",
    "A,B,C =factors\n",
    "\n",
    "\n",
    "G_f = np.zeros((28,300))\n",
    "for i in range(28):\n",
    "    G_f[i] = G[:,:,:,i].flatten()\n",
    "\n",
    "G_test = tensorly.tenalg.multi_mode_dot(tnsr_test, [x.T for x in factors], modes=[0,1,2])\n",
    "\n",
    "G_test_f = np.zeros((12,300))\n",
    "for i in range(12):\n",
    "    G_test_f[i] = G_test[:,:,:,i].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16666666666666663"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=2,n_estimators=100)\n",
    "clf.fit(G_f, y_train)\n",
    "y_hat = clf.predict(G_test_f)\n",
    "# error rate\n",
    "1-accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "The error rate for the grayscale and color images was 0.08 and 0.17 respectively with a random forest using 100 trees and a max depth of 2. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omsa",
   "language": "python",
   "name": "omsa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
