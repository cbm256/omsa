{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part a:\n",
    "\n",
    "\n",
    "show that:\n",
    "\n",
    "$$\\hat{\\beta}=X^Ty$$\n",
    "\n",
    "Is a closed form solution for the Ordinary Least Squares regression problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: The Elements of Statistical Learning <br />\n",
    "\n",
    "Least squares pick $\\beta$ coefficients by minimizing the residual sum of squares (RSS)\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "RSS(\\beta) &= \\sum_{i=1}^N(y_i - f(x_i))^2 \\\\\n",
    "           &= \\sum_{i=1}^N \\Bigg( y_i-\\beta_0-\\sum_{j=1}^P x_{ij} \\beta_j \\Bigg)^2\n",
    "\\end{split}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denote by $X$ the $N \\times (p + 1)$ matrix with\n",
    "each row an input vector (with a 1 in the first position), and similarly let\n",
    "$y$ be the $N$ -vector of outputs in the training set. Then we can write the\n",
    "residual sum-of-squares as:\n",
    "\n",
    "$$RSS = (y-X \\beta)^T(y-X \\beta)$$\n",
    "\n",
    "This is a quadratic function in the $p + 1$ parameters. Differentiating with\n",
    "respect to $\\beta$ we obtain:\n",
    "\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\frac{\\partial RSS }{\\partial \\beta } &= -2X^T(y-X \\beta) \\\\\n",
    "\\frac{\\partial^2 RSS }{\\partial \\beta \\partial \\beta^T } &=2X^TX\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming (for the moment) that $X$ has full column rank, and hence $X^T X$\n",
    "is positive definite, we set the first derivative to zero:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "& X^T(y- X \\beta) = 0 \\\\\n",
    " \\text{ Solve for } \\beta \\text{:  }& \\\\\n",
    "& \\hat \\beta = (X^TX)^{-1}X^Ty\n",
    "\\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming $X$ is orthonormal $X^TX=(X^TX)^{-1}=I^P$ where $I^P$ is a $p \\times p$ identity matrix.  The fitted values at the training inputs are:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\hat y &= X(X^TX)^{-1}X^Ty = X \\hat \\beta \\\\\n",
    "      &=XIX^Ty=X \\hat \\beta \\\\\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "Reducing the above and solving for $\\hat \\beta $ gives:\n",
    "\n",
    "$$\\hat{\\beta}=X^Ty$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part b\n",
    "\n",
    "Starting with the RSS in matrix form we have:\n",
    "\n",
    "$$RSS(\\lambda)=(y-X \\beta)^T(y-X\\beta) + \\lambda \\beta^T \\beta$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differentiating with respect to then solving for $ \\beta $, \n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\frac{\\partial RSS }{\\partial \\beta } &= -2X^T(y-X \\beta) + 2\\lambda \\beta\\\\\n",
    "\\beta^{ridge} &= (X^TX+ \\lambda I)^{-1}X^Ty\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since X is orthonormal and we already know from part a above that $\\beta^{ols} = X^Ty$\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\beta^{ridge} =& (I + \\lambda I)^{-1}X^Ty \\\\\n",
    " =&(1+ \\lambda)^{-1}X^Ty \\\\\n",
    " =&(1+ \\lambda)^{-1} \\beta^{ols}\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part c\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "RSS(\\lambda)=&(y-X \\beta)^T(y-X\\beta) \\lambda |\\beta| \\\\\n",
    "\\frac{\\partial RSS }{\\partial \\beta } =& -2X^T(y-X \\beta)  \\lambda \\frac{\\partial }{\\partial \\beta }| \\beta| \\\\\n",
    "0 =& -2X^Ty 2X^TX \\beta\\lambda \\frac{\\partial }{\\partial \\beta }| \\beta| \\\\\n",
    "0 =& -2 \\beta^{ols} 2I \\beta \\lambda \\frac{\\partial }{\\partial \\beta }| \\beta| \\\\\n",
    "0= &-2 \\beta^{Ols}_j+2 \\beta_j + \\lambda \\frac{\\partial }{\\partial \\beta }| \\beta|\n",
    "\\end{split}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The three cases on the sign for the partial derivative on the absolute value of $\\beta$\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "0= &-2 \\beta^{Ols}_j+2 \\beta_j + \\lambda \\\\\n",
    "0= &-2 \\beta^{Ols}_j+2 \\beta_j - \\lambda\\\\\n",
    "0= &-2 \\beta^{Ols}_j+2 \\beta_j\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "Which is the closed form solution:\n",
    "\\begin{equation}\n",
    "\\hat{\\beta}^{lasso}_j =\n",
    "\\begin{cases}\n",
    "  \\beta^{ols}_j-\\frac{\\lambda}{2} \\text{ if }\\beta^{ols}_j>frac{\\lambda}{2}\\\\    \n",
    "  0    \\text{ if }-\\frac{\\lambda}{2}\\leq\\beta^{ols}_j\\leq\\frac{\\lambda}{2}\\\\\n",
    "  \\beta^{ols}_j+\\frac{\\lambda}{2}\\text{ if }\\beta^{ols}_j<-\\frac{\\lambda}{2}\n",
    "\\end{cases}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Didn't have time for part d, going camping for the holiday weekend :("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omsa",
   "language": "python",
   "name": "omsa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
