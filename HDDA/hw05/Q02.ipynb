{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = loadmat('ratings.mat')[\"M0\"]\n",
    "missing = loadmat('ratings_missing.mat')[\"M1\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "\tSCS v2.0.2 - Splitting Conic Solver\n",
      "\t(c) Brendan O'Donoghue, Stanford University, 2012-2017\n",
      "----------------------------------------------------------------------------\n",
      "Lin-sys: sparse-indirect, nnz in A = 75150, CG tol ~ 1/iter^(2.00)\n",
      "eps = 1.00e-04, alpha = 1.50, max_iters = 5000, normalize = 1, scale = 1.00\n",
      "acceleration_lookback = 20, rho_x = 1.00e-03\n",
      "Variables n = 45150, constraints m = 75150\n",
      "Cones:\tprimal zero / dual free vars: 10000\n",
      "\tlinear vars: 20000\n",
      "\tsd vars: 45150, sd blks: 1\n",
      "Setup time: 5.53e-02s\n",
      "----------------------------------------------------------------------------\n",
      " Iter | pri res | dua res | rel gap | pri obj | dua obj | kap/tau | time (s)\n",
      "----------------------------------------------------------------------------\n",
      "     0| 2.89e+21  3.75e+21  1.00e+00 -1.12e+25  1.71e+25  1.58e+24  8.08e-02 \n",
      "   100| 1.44e-03  2.07e-03  1.98e-03  9.64e+02  9.61e+02  4.51e-13  3.88e+00 \n",
      "   200| 1.19e-04  1.64e-04  6.01e-05  9.66e+02  9.66e+02  3.16e-13  7.17e+00 \n",
      "   240| 4.60e-05  6.13e-05  2.47e-06  9.65e+02  9.65e+02  9.10e-13  8.45e+00 \n",
      "----------------------------------------------------------------------------\n",
      "Status: Solved\n",
      "Timing: Solve time: 8.45e+00s\n",
      "\tLin-sys: avg # CG iterations: 1.00, avg solve time: 8.74e-04s\n",
      "\tCones: avg projection time: 2.25e-02s\n",
      "\tAcceleration: avg step time: 9.50e-03s\n",
      "----------------------------------------------------------------------------\n",
      "Error metrics:\n",
      "dist(s, K) = 3.9348e-07, dist(y, K*) = 6.1075e-08, s'y/|s||y| = -6.0854e-10\n",
      "primal res: |Ax + s - b|_2 / (1 + |b|_2) = 4.6023e-05\n",
      "dual res:   |A'y + c|_2 / (1 + |c|_2) = 6.1260e-05\n",
      "rel gap:    |c'x + b'y| / (1 + |c'x| + |b'y|) = 2.4652e-06\n",
      "----------------------------------------------------------------------------\n",
      "c'x = 965.4403, -b'y = 965.4450\n",
      "============================================================================\n"
     ]
    }
   ],
   "source": [
    "mask = missing != 0\n",
    "m,n = ratings.shape\n",
    "x = cp.Variable((m,n))\n",
    "objective = cp.Minimize(cp.normNuc(x))\n",
    "constraints = [x[mask] == ratings[mask], x>=1]\n",
    "prob = cp.Problem(objective, constraints)\n",
    "result = prob.solve(solver='SCS', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "344.4646372724289"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(ratings-x.value)/ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = missing\n",
    "n1,n2 = A.shape\n",
    "r = 2\n",
    "u, s, vh = np.linalg.svd(A)\n",
    "s[r:] = 0\n",
    "\n",
    "mask = missing == 0\n",
    "m = (~mask).sum()\n",
    "Y = np.zeros((n1, n2))\n",
    "delta = n1*n2/m\n",
    "tau = 500\n",
    "# %Iterations\n",
    "vec = []\n",
    "err = []\n",
    "for i in range(500):\n",
    "    u, s, vh = np.linalg.svd(Y)\n",
    "    s_t = np.maximum(s-tau, 0)\n",
    "    Z = (u[:, :n2]*s_t)@vh\n",
    "    P = missing-Z\n",
    "    P[mask] = 0\n",
    "    Y0 = Y.copy()\n",
    "    Y = Y0 + delta*P\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "391.8841094041523"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(ratings-Z)/ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat_comp(A,tau,delta):\n",
    "    n1,n2 = A.shape\n",
    "    r = 2\n",
    "    u, s, vh = np.linalg.svd(A)\n",
    "    s[r:] = 0\n",
    "    mask = missing == 0\n",
    "    m = (~mask).sum()\n",
    "    Y = np.zeros((n1, n2))\n",
    "    for i in range(500):\n",
    "        u, s, vh = np.linalg.svd(Y)\n",
    "        s_t = np.maximum(s-tau, 0)\n",
    "        Z = (u[:, :n2]*s_t)@vh\n",
    "        P = A-Z\n",
    "        P[mask] = 0\n",
    "        Y0 = Y.copy()\n",
    "        Y = Y0 + delta*P\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tau: 50 delta: 0.1 Error: 4533.8829608937085\n",
      "tau: 50 delta: 2 Error: 4555.1019317726505\n",
      "tau: 500 delta: 0.1 Error: 931.1822789332377\n",
      "tau: 500 delta: 2 Error: 391.8841094041523\n"
     ]
    }
   ],
   "source": [
    "iters = [(.1,50),(2,50),(.1,500),(2,500)]\n",
    "\n",
    "for iter in iters:\n",
    "    delta,tau = iter\n",
    "    Z = mat_comp(missing,tau,delta)\n",
    "    error = np.sum(np.abs(ratings-Z)/ratings)\n",
    "    print(f\"tau: {tau} delta: {delta} Error: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C\n",
    "\n",
    "The singular value thresholding algorithm executed much faster than the cvxpy implementation of nuclear norm minimization with the same reconstruction error, once tau and delta were known.  Terefore it is the better method."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omsa",
   "language": "python",
   "name": "omsa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
